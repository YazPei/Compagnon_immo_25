
# ========== Makefile MLOps ==========
# Pipelines R√©gression + S√©ries temporelles
# Outils : DVC, MLflow, Docker, bash scripts
IMAGE_PREFIX=compagnon_immo

# ===============================
# Aide
# ===============================

help: ## Affiche l'aide
	@echo "========== Compagnon Immo - Commandes disponibles =========="
	@echo ""
	@grep -E '^[a-zA-Z_-]+:.*?##.*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-30s\033[0m %s\n", $$1, $$2}'
	@echo ""


# ===============================
# üì¶ Setup initial
# ===============================

install:
	@echo "üì¶ V√©rification de l'environnement virtuel..."
	@if [ ! -f ".venv/bin/activate" ]; then \
		echo "‚öôÔ∏è  Cr√©ation de l'environnement virtuel (.venv)"; \
		python3 -m venv .venv; \
	else \
		echo "‚úÖ Environnement virtuel d√©j√† pr√©sent"; \
	fi

	@echo "üì¶ V√©rification des paquets install√©s..."
	@if [ ! -d ".venv/lib" ] || ! . .venv/bin/activate && pip list | grep -Fq -f requirements.txt; then \
		echo "üì¶ Installation des d√©pendances..."; \
		. .venv/bin/activate && pip install --upgrade pip && pip install -r requirements.txt; \
	else \
		echo "‚úÖ D√©pendances d√©j√† install√©es"; \
	fi


# ===========================================================
# üß™ Pipelines ML (Local) pour rendre les scripts ex√©cutables
# ===========================================================

chmod-scripts: ## Rend les scripts ex√©cutables
	@chmod +x mlops/fusion/run_fusion.sh
	@chmod +x mlops/preprocessing/run_preprocessing.sh
	@chmod +x mlops/clustering/run_clustering.sh
	@chmod +x mlops/Regression/run_all.sh
	@chmod +x mlops/Serie_temporelle/run_all_st.sh
	@chmod +x run_all_full.sh

fusion: chmod-scripts ## Fusion des donn√©es via DVC
	@echo "Fusion des donn√©es via DVC (local)"
	@bash mlops/fusion/run_fusion.sh

preprocessing: chmod-scripts ## Pr√©traitement des donn√©es
	@echo "Pr√©traitement des donn√©es (local via DVC)"
	@bash mlops/preprocessing/run_preprocessing.sh

clustering: chmod-scripts ## Clustering KMeans
	@echo "Lancement du clustering KMeans (local via DVC)"
	@bash mlops/clustering/run_clustering.sh

regression: chmod-scripts ## Pipeline de r√©gression
	@echo "Lancement pipeline R√©gression (local)"
	@bash mlops/Regression/run_all.sh

series: chmod-scripts ## Pipeline de s√©ries temporelles
	@echo "‚è≥ Lancement pipeline S√©rie Temporelle (local)"
	@bash mlops/Serie_temporelle/run_all_st.sh

ml-pipeline: fusion preprocessing clustering regression ## Pipeline ML complet
	@echo "Pipeline ML complet termin√©"

# ===============================
# üåê API et Interface Web
# ===============================

api-dev: check-env ## D√©marre l'API en mode d√©veloppement
	@echo "üöÄ D√©marrage de l'API..."
	@echo "üìç API : http://localhost:8000"
	@echo "üìö Docs : http://localhost:8000/docs"
	@cd api_test && ../.venv/bin/python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000


streamlit: check-env ## D√©marre l'interface Streamlit
	@echo "üé® D√©marrage de Streamlit..."
	@echo "üìç Interface : http://localhost:8501"
	@cd api_test && ../.venv/bin/streamlit run questionnaire_streamlit.py --server.port 8501

api-test: check-env ## Lance les tests de l'API
	@echo "üß™ Tests de l'API..."
	@cd api_test && ../.venv/bin/python -m pytest app/tests/ -v

dev-env: ## Environnement de d√©veloppement complet
	@echo "üõ†Ô∏è D√©marrage de l'environnement complet..."
	@echo "D√©marrage en parall√®le : MLflow + API + Streamlit"
	@make -j3 mlflow-ui api-dev streamlit


# ===============================
# üìà MLflow
# ===============================

mlflow-ui: check-env ## D√©marre l'interface MLflow
	@echo "üìà D√©marrage de l'interface MLflow"
	@echo "üìç MLflow UI disponible sur : http://localhost:5001"
	@../.venv/bin/mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0 --port 5001

mlflow-clean: ## Nettoie les runs MLflow
	@echo "üßπ Suppression du r√©pertoire mlruns/"
	@rm -rf mlruns/

mlflow-status: ## Affiche le statut des derniers runs
	@echo "üìú Derniers runs MLflow"
	@find mlruns/ -name "meta.yaml" 2>/dev/null | xargs grep -H "status" || echo "Aucun run trouv√©"


# ===============================
# üê≥ Docker - API
# ===============================

docker-build: ## Construction des images Docker
	@echo "üîß Construction des images..."
	@docker-compose build

docker-api-build: ## Construction de l'image Docker API
	@echo "Construction de l'image Docker API"
	@cd api_test && docker build -t compagnon-immo-api .

docker-api-run: docker-api-build ## Lance l'API dans Docker
	@echo "Lancement de l'API dans Docker"
	@echo "API disponible sur : http://localhost:8000"
	@docker run -p 8000:8000 --name compagnon-api compagnon-immo-api

docker-stack-up: ## D√©marre la stack Docker compl√®te
	@echo "üê≥ D√©marrage de la stack..."
	@docker-compose up -d
	@echo "‚úÖ Stack d√©marr√©e"

docker-stack-down: ## Arr√™te la stack Docker
	@echo "üõë Arr√™t de la stack..."
	@docker-compose down

docker-logs: ## Affiche les logs Docker
	@docker-compose logs -f

# ===============================
# ‚òÅÔ∏è Setup remote DagsHub
# ===============================

setup_dags:  ## Configure le remote DVC vers DagsHub (secure, local only)
	@echo "‚òÅÔ∏è Configuration du remote DVC (DagsHub s√©curis√©)"
	@chmod +x setup_remote.sh
	@./setup_remote.sh

# 
# ===============================
# üê≥ Ex√©cution dans Docker
# ===============================


docker_auto: build-all run-all-docker

## builds ##
build-all: build-base build-fusion build-preprocessing build-clustering build-encoding build-lgbm build-analyse build-splitST build-decompose build-SARIMAX build-evaluate
	@echo "üì¶ Toutes les images Docker ont √©t√© construites avec succ√®s !"

docker_build:
	@echo "üîß Construction de l‚Äôimage Docker..."
	docker build -f Dockerfile.run -t $(IMAGE_PREFIX)-run .
	
build-base: ## Build de l'image Docker de base (requirements install√©s)
	docker build -f Dockerfile.dvc -t $(IMAGE_PREFIX)-dvc .


		
build-fusion: ## Build de l'image Docker d'enrichissement du dataset
	docker build -f Dockerfile.fusion -t $(IMAGE_PREFIX)-fus .
	
build-preprocessing: ## Build de l'image Docker de preprocessing
	docker build -f Dockerfile.preprocessing -t $(IMAGE_PREFIX)-preprocess .
	
build-clustering: ## Build de l'image Docker de segmentation geographique
	docker build -f Dockerfile.clustering -t $(IMAGE_PREFIX)-clust .
	
build-encoding: ## Build de l'image Docker d'encoding
	docker build -f Dockerfile.encoding.REG -t $(IMAGE_PREFIX)-encod .
	
build-lgbm: ## Build de l'image Docker de la modelisation Regression
	docker build -f Dockerfile.lgbm.REG -t $(IMAGE_PREFIX)-lgbm .
	
build-util: ## Build de l'image Docker d'interpretabilit√©
	docker build -f Dockerfile.analyse.REG -t $(IMAGE_PREFIX)-util .
		
build-analyse: ## Build de l'image Docker d'interpretabilit√©
	docker build -f Dockerfile.analyse.REG -t $(IMAGE_PREFIX)-shap .
	
build-splitst: ## Build de l'image Docker du Split de la serie temporelle
	docker build -f Dockerfile.split.ST -t $(IMAGE_PREFIX)-split-st .
				
build-decompose: ## Build de l'image Docker de la d√©composition des courbes
	docker build -f Dockerfile.decompose.ST -t $(IMAGE_PREFIX)-decomp .
			
build-SARIMAX: ## Build de l'image Docker de la modelisation SARIMAX 
	docker build -f Dockerfile.sarimax.ST -t $(IMAGE_PREFIX)-sarimax .		

build-evaluate: ## Build de l'image Docker de l'√©valuation du mod√®le SARIMAX
	docker build -f Dockerfile.evaluate.ST -t $(IMAGE_PREFIX)-evalu .		

run-all-docker: run_full run_dvc run_fusion run_preprocessing run_clustering run_lgbm run_analyse run_splitst run_decompose run_SARIMAX run_evaluate ## lancement de tous les containers 
	@echo "üöÄ Pipeline complet ex√©cut√© dans Docker !"

run_full:
	@echo "üöÄ Ex√©cution pipeline lancement"
	docker run --rm -f $(IMAGE_PREFIX)-run

run_dvc: ## lancement du dvc
	@echo "dvc..."
	docker run --rm -f $(IMAGE_PREFIX)-dvc
											
run_fusion: ## Lancement de la fusion des donn√©es (Docker)
	@echo "üåê Fusion des donn√©es IPS et g√©ographiques (Docker)"
	docker run --rm -f $(IMAGE_PREFIX)-fus

run_preprocessing: ## Lancement du preprocessing (Docker)
	@echo "üßº Ex√©cution preprocessing (Docker)"
	docker run --rm -f $(IMAGE_PREFIX)-preprocess

run_clustering: ## Lancement du clustering (Docker)
	@echo "üìä Ex√©cution du clustering (Docker)"
	docker run --rm -f $(IMAGE_PREFIX)-clust
	
run_lgbm: ## Lancement de la r√©gression LGBM (Docker)
	@echo "üîÅ Ex√©cution pipeline R√©gression (Docker)"
	docker run --rm -f $(IMAGE_PREFIX)-lgbm
	
build-util: ## Build de l'image Docker d'interpretabilit√©
	docker run --rm -f $(IMAGE_PREFIX)-util
	
run_analyse: ## Build de l'image Docker d'interpretabilit√©
	docker run --rm -f $(IMAGE_PREFIX)-shap
	
run_splitst: ## Build de l'image Docker du Split de la serie temporelle
	docker run --rm -f $(IMAGE_PREFIX)--split-st
				
run_decompose: ## Build de l'image Docker de la d√©composition des courbes
	docker run --rm -f $(IMAGE_PREFIX)-decomp
			
run_SARIMAX: ## Build de l'image Docker de la modelisation SARIMAX 
	docker run --rm -f $(IMAGE_PREFIX)-sarimax		

run_evaluate: ## Build de l'image Docker de l'√©valuation du mod√®le SARIMAX
	docker run --rm -f $(IMAGE_PREFIX)-evalu	

		
# ===============================
# üìÅ Commandes DVC (via Docker)
# ===============================
dvc-all: build-dvc-image run-dvc-repro dvc-metrics dvc-push dvc-save ## Reproduit, affiche les m√©triques et push
	@echo "‚úÖ Pipeline DVC complet ex√©cut√© et synchronis√©"

	
build-dvc-image: ## Build de l'image Docker DVC + DagsHub
	docker build -f Dockerfile.dvc -t $(IMAGE_PREFIX)-dvc .
		
run-dvc-repro: ## Ex√©cution du pipeline DVC (repro) dans un conteneur DVC
	docker compose run --rm dvc-runner dvc repro
	####	
dvc-push: ## Push vers DagsHub en Docker
	docker run --rm \
		-v $(PWD):/app \
		-v ~/.dvc/config.local:/app/.dvc/config.local:ro \
		-w /app \
		$(IMAGE_PREFIX)-dvc \
		push


dvc-pull: ## Pull depuis DagsHub en Docker
	docker run --rm \
		-v $(PWD):/app \
		-v ~/.dvc/config.local:/app/.dvc/config.local:ro \
		-w /app \
		$(IMAGE_PREFIX)-dvc \
		pull

dvc-metrics: ## Affiche les m√©triques DVC via Docker
	docker run --rm \
		-v $(PWD):/app \
		-v ~/.dvc/config.local:/app/.dvc/config.local:ro \
		-w /app \
		$(IMAGE_PREFIX)-dvc \
		metrics show
		
dvc-plots: ## G√©n√®re les graphiques DVC (plots.html) via Docker
	docker run --rm \
		-v $(PWD):/app \
		-v ~/.dvc/config.local:/app/.dvc/config.local:ro \
		-w /app \
		$(IMAGE_PREFIX)-dvc \
		plots show --html > plots.html && echo "Fichier 'plots.html' g√©n√©r√©"
		
dvc-save: ## Ajoute, commit et tag un fichier .dvc modifi√©
	dvc add data/processed/train_clean.csv
	git add data/processed/train_clean.csv.dvc
	git commit -m "DVC update train_clean"
					
# ===============================
# üßπ Nettoyage
# ===============================

clean_exports:
	@echo "üßπ Suppression des fichiers exports/"
	rm -rf exports/reg/*.csv exports/reg/*.joblib
	rm -rf exports/st/*.csv exports/st/*.pkl exports/st/*.png exports/st/*.json

clean_dvc:
	@echo "üßπ Nettoyage DVC cache non utilis√© (local uniquement)"
	dvc gc -w --force

clean_all: clean_exports clean_dvc




# ===============================
# üìà Tracking MLflow
# ===============================

mlflow-ui:
	@echo "üìà D√©marrage de l‚Äôinterface MLflow sur http://localhost:5001"
	mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0 --port 5001

mlflow-run:
	@echo "üöÄ Lancement manuel d‚Äôun run MLflow (ex: clustering)"
	python -m src.clustering \
		--input-path data/processed/train_clean.csv \
		--output-path data/interim

mlflow-clean:
	@echo "üßπ Suppression du r√©pertoire mlruns/"
	rm -rf mlruns/s

mlflow-log-status:
	@echo "üìú Derniers runs MLflow"
	@find mlruns/ -name "meta.yaml" | xargs grep -H "status"


# ===============================
# üß™ Tests complets
# ===============================

test-ml: check-env ## Tests des pipelines ML
	@echo "üß™ Tests ML..."
	@pytest mlops/tests/ -v || echo "Dossier mlops/tests/ non trouv√©"

test-all: test-ml api-test ## Tous les tests
	@echo "‚úÖ Tous les tests termin√©s"

# ===============================
# üöÄ Pipelines complets
# ===============================

full-stack: install ml-pipeline api-dev ## Pipeline ML + API
	@echo "üéâ Pipeline complet + API d√©marr√©s !"

quick-start: install full-stack streamlit ## Installation et d√©marrage rapide
	@echo "üöÄ Projet pr√™t √† utiliser !"

# ===============================
# üîç Utilitaires
# ===============================

status: ## Affiche le statut du projet
	@echo "========== Statut du projet =========="
	@echo "Dossier : $(PWD)"
	@echo "Python : $$(python3 --version 2>/dev/null || echo 'Non install√©')"
	@echo "Env virtuel : $$([ -f .venv/bin/activate ] && echo '‚úÖ Pr√©sent' || echo '‚ùå Absent')"
	@echo "Docker : $$(docker --version 2>/dev/null || echo 'Non install√©')"
	@echo "DVC : $$(dvc --version 2>/dev/null || echo 'Non install√©')"
	@echo "Donn√©es : $$([ -d data ] && echo '‚úÖ Pr√©sent' || echo '‚ùå Absent')"

ports-check: ## V√©rifie les ports utilis√©s
	@echo "V√©rification des ports..."
	@echo "Port 8000 (API) : $$(lsof -ti:8000 && echo 'Occup√©' || echo 'Libre')"
	@echo "Port 8501 (Streamlit) : $$(lsof -ti:8501 && echo 'Occup√©' || echo 'Libre')"
	@echo "Port 5001 (MLflow) : $$(lsof -ti:5001 && echo 'Occup√©' || echo 'Libre')"
