cat > Makefile.s3 << 'EOF'
# Makefile S3 (DagsHub) — sans TAB grâce à RECIPEPREFIX
SHELL := /usr/bin/env bash
.RECIPEPREFIX := >

S3_VENV := .s3venv
S3_PY   := $(S3_VENV)/bin/python
S3_PIP  := $(S3_VENV)/bin/pip

S3_FILE ?= merged_sales_data.csv
S3_KEY  ?= merged_sales_data.csv

.PHONY: s3-help s3-venv s3-install s3-env s3-sanity s3-upload s3-upload-mp s3-list s3-clean

s3-help: ## Aide section S3 (DagsHub)
> echo "S3 targets: s3-venv s3-install s3-env s3-sanity s3-upload s3-upload-mp s3-list s3-clean"

s3-venv:
> python3 -m venv $(S3_VENV)
> $(S3_PIP) -q install --upgrade pip

s3-install: s3-venv
> $(S3_PIP) -q install boto3 botocore

s3-env:
> test -f $$HOME/.dagshub.env || (echo "Missing $$HOME/.dagshub.env"; exit 1)
> set -a; source $$HOME/.dagshub.env; set +a; \
> echo "Endpoint: $$AWS_S3_ENDPOINT"; \
> echo "Bucket  : $$DAGSHUB_BUCKET"; \
> echo "Region  : $$AWS_DEFAULT_REGION"

s3-sanity: s3-env
> set -a; source $$HOME/.dagshub.env; set +a; \
> $(S3_PY) - <<'PY' || { echo "Sanity FAIL"; exit 3; }
> import os, boto3
> s3=boto3.client("s3",
>   endpoint_url=os.environ["AWS_S3_ENDPOINT"],
>   aws_access_key_id=os.environ["AWS_ACCESS_KEY_ID"],
>   aws_secret_access_key=os.environ["AWS_SECRET_ACCESS_KEY"],
>   region_name=os.environ.get("AWS_DEFAULT_REGION","us-east-1"))
> b=os.environ["DAGSHUB_BUCKET"]
> resp=s3.list_objects_v2(Bucket=b, MaxKeys=5)
> print("Sanity OK. KeyCount:", resp.get("KeyCount",0))
> PY

# Requiert tools/upload_s3_resilient.py
s3-upload: s3-env
> set -a; source $$HOME/.dagshub.env; set +a; \
> $(S3_PY) tools/upload_s3_resilient.py "$(S3_FILE)" "$$DAGSHUB_BUCKET" "$(S3_KEY)" \
>   --endpoint-url "$$AWS_S3_ENDPOINT" --path-style --force-single --verbose

s3-upload-mp: s3-env
> set -a; source $$HOME/.dagshub.env; set +a; \
> $(S3_PY) tools/upload_s3_resilient.py "$(S3_FILE)" "$$DAGSHUB_BUCKET" "$(S3_KEY)" \
>   --endpoint-url "$$AWS_S3_ENDPOINT" --path-style \
>   --chunk-size-mb 8 --multipart-threshold-mb 16 --max-concurrency 2 --verbose

s3-list: s3-env
> set -a; source $$HOME/.dagshub.env; set +a; \
> $(S3_PY) - <<'PY'
> import os, boto3
> s3=boto3.client("s3",
>   endpoint_url=os.environ["AWS_S3_ENDPOINT"],
>   aws_access_key_id=os.environ["AWS_ACCESS_KEY_ID"],
>   aws_secret_access_key=os.environ["AWS_SECRET_ACCESS_KEY"],
>   region_name=os.environ.get("AWS_DEFAULT_REGION","us-east-1"))
> b=os.environ["DAGSHUB_BUCKET"]
> resp=s3.list_objects_v2(Bucket=b, MaxKeys=50)
> for o in resp.get("Contents",[]) or []:
>     print(o["Key"])
> PY

s3-clean:
> rm -rf $(S3_VENV) __pycache__ .pytest_cache
EOF

