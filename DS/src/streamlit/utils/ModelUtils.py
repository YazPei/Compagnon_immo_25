################################################################################
#                                                                              #
#                          ANALYSE ET MODÃ‰LISATION                             #
#                                                                              #
################################################################################
"""
Module contenant les fonctions d'analyse, d'Ã©valuation, de visualisation et de gestion
des modÃ¨les pour un projet d'analyse immobiliÃ¨re basÃ© sur Streamlit, pandas et scikit-learn.

Ce module complÃ¨te Encoding.py en fournissant des outils pour l'analyse des donnÃ©es,
l'optimisation des modÃ¨les, l'interprÃ©tation des rÃ©sultats et la sauvegarde/chargement
des modÃ¨les et features.
"""

# Standard library
import os
import warnings
from typing import List, Dict, Tuple, Union, Optional, Any, Callable

# Data manipulation
import numpy as np
import pandas as pd

# Machine learning
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.pipeline import Pipeline

# Model saving/loading
try:
    import joblib
    HAS_JOBLIB = True
except ImportError:
    HAS_JOBLIB = False
    warnings.warn("Le module joblib n'est pas installÃ©. "
                 "Les fonctionnalitÃ©s de sauvegarde/chargement de modÃ¨les seront limitÃ©es.")

# Hyperparameter optimization
try:
    import optuna
    from optuna.integration import OptunaSearchCV
    import optuna.visualization as vis
    HAS_OPTUNA = True
except ImportError:
    HAS_OPTUNA = False
    warnings.warn("Le module optuna n'est pas installÃ©. "
                 "Les fonctionnalitÃ©s d'optimisation d'hyperparamÃ¨tres seront limitÃ©es.")

# Model interpretation
try:
    import shap
    HAS_SHAP = True
except ImportError:
    HAS_SHAP = False
    warnings.warn("Le module shap n'est pas installÃ©. "
                 "Les fonctionnalitÃ©s d'interprÃ©tation de modÃ¨les seront limitÃ©es.")

# LightGBM
try:
    from lightgbm import LGBMRegressor
    HAS_LIGHTGBM = True
except ImportError:
    HAS_LIGHTGBM = False
    warnings.warn("Le module lightgbm n'est pas installÃ©. "
                 "Les fonctionnalitÃ©s de modÃ©lisation LightGBM seront limitÃ©es.")

try:
    from optuna.integration import OptunaSearchCV
except ImportError:
    OptunaSearchCV = None


################################################################################
####################### Ã‰CHANTILLONNAGE ET PRÃ‰PARATION #########################
################################################################################

def create_stratified_sample(df: pd.DataFrame, 
                           target_col: str = "prix_m2_vente",
                           train_size: float = 0.2,
                           n_bins: int = 10,
                           random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    CrÃ©e un Ã©chantillon stratifiÃ© Ã  partir d'un DataFrame.
    
    Args:
        df (pd.DataFrame): DataFrame source
        target_col (str): Nom de la colonne cible pour la stratification
        train_size (float): Proportion de l'Ã©chantillon Ã  extraire
        n_bins (int): Nombre de bins pour la stratification
        random_state (int): Graine alÃ©atoire pour la reproductibilitÃ©
        
    Returns:
        Tuple[pd.DataFrame, pd.DataFrame]: Ã‰chantillon stratifiÃ© et reste des donnÃ©es
    """
    df = df.copy()
    
    # CrÃ©ation des bins pour la stratification
    df["target_bin"] = pd.qcut(
        df[target_col], 
        q=n_bins, 
        duplicates="drop"
    )
    
    # Ã‰chantillonnage stratifiÃ©
    sample, rest = train_test_split(
        df,
        train_size=train_size,
        stratify=df["target_bin"],
        random_state=random_state
    )
    
    # Suppression de la colonne temporaire
    sample = sample.drop(columns=["target_bin"])
    rest = rest.drop(columns=["target_bin"])
    
    return sample, rest


def prepare_train_test_data(df: pd.DataFrame, 
                          features: List[str],
                          target_col: str = "prix_m2_vente",
                          test_size: float = 0.2,
                          random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """
    PrÃ©pare les donnÃ©es d'entraÃ®nement et de test Ã  partir d'un DataFrame.
    
    Args:
        df (pd.DataFrame): DataFrame source
        features (List[str]): Liste des colonnes Ã  utiliser comme features
        target_col (str): Nom de la colonne cible
        test_size (float): Proportion des donnÃ©es Ã  utiliser pour le test
        random_state (int): Graine alÃ©atoire pour la reproductibilitÃ©
        
    Returns:
        Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]: X_train, X_test, y_train, y_test
    """
    # CrÃ©ation des bins pour la stratification
    df["target_bin"] = pd.qcut(
        df[target_col], 
        q=10, 
        duplicates="drop"
    )
    
    # Split train/test stratifiÃ©
    train_df, test_df = train_test_split(
        df,
        test_size=test_size,
        stratify=df["target_bin"],
        random_state=random_state
    )
    
    # Suppression de la colonne temporaire
    train_df = train_df.drop(columns=["target_bin"])
    test_df = test_df.drop(columns=["target_bin"])
    
    # Extraction des features et de la cible
    X_train = train_df[features]
    y_train = train_df[target_col]
    X_test = test_df[features]
    y_test = test_df[target_col]
    
    return X_train, X_test, y_train, y_test


################################################################################
####################### OPTIMISATION DES HYPERPARAMÃˆTRES #######################
################################################################################

def create_optuna_search_space() -> Dict[str, Any]:
    """
    CrÃ©e un espace de recherche pour l'optimisation des hyperparamÃ¨tres avec Optuna.
    
    Returns:
        Dict[str, Any]: Dictionnaire des distributions de paramÃ¨tres
        
    Raises:
        ImportError: Si optuna n'est pas installÃ©
    """
    if not HAS_OPTUNA:
        raise ImportError("Cette fonction nÃ©cessite optuna. "
                         "Installez-le avec 'pip install optuna'.")
    
    param_distributions = {
        "model__num_leaves":       optuna.distributions.IntDistribution(16, 64),
        "model__learning_rate":    optuna.distributions.FloatDistribution(1e-3, 0.2, log=True),
        "model__n_estimators":     optuna.distributions.IntDistribution(50, 500),
        "model__max_depth":        optuna.distributions.IntDistribution(3, 8),
        "model__subsample":        optuna.distributions.FloatDistribution(0.5, 1.0),
        "model__colsample_bytree": optuna.distributions.FloatDistribution(0.5, 1.0),
        "model__reg_alpha":        optuna.distributions.FloatDistribution(0.0, 2.0),
        "model__reg_lambda":       optuna.distributions.FloatDistribution(0.0, 2.0),
    }
    
    return param_distributions


def optimize_hyperparameters(pipeline: Pipeline, 
                           X_train: pd.DataFrame, 
                           y_train: pd.Series,
                           param_distributions: Optional[Dict[str, Any]] = None,
                           n_trials: int = 30,
                           cv: int = 5,
                           scoring: str = "r2",
                           n_jobs: int = -1,
                           random_state: int = 42,
                           verbose: int = 1) -> OptunaSearchCV:
    """
    Optimise les hyperparamÃ¨tres d'un pipeline avec Optuna.
    
    Args:
        pipeline (Pipeline): Pipeline scikit-learn Ã  optimiser
        X_train (pd.DataFrame): Features d'entraÃ®nement
        y_train (pd.Series): Cible d'entraÃ®nement
        param_distributions (Optional[Dict[str, Any]]): Espace de recherche des hyperparamÃ¨tres
        n_trials (int): Nombre d'essais pour l'optimisation
        cv (int): Nombre de folds pour la validation croisÃ©e
        scoring (str): MÃ©trique d'Ã©valuation
        n_jobs (int): Nombre de jobs parallÃ¨les (-1 pour utiliser tous les cÅ“urs)
        random_state (int): Graine alÃ©atoire pour la reproductibilitÃ©
        verbose (int): Niveau de verbositÃ©
        
    Returns:
        OptunaSearchCV: Objet OptunaSearchCV ajustÃ©
        
    Raises:
        ImportError: Si optuna n'est pas installÃ©
    """
    if not HAS_OPTUNA:
        raise ImportError("Cette fonction nÃ©cessite optuna. "
                         "Installez-le avec 'pip install optuna'.")
    
    # Utiliser l'espace de recherche par dÃ©faut si aucun n'est fourni
    if param_distributions is None:
        param_distributions = create_optuna_search_space()
    
    # Configuration de l'optimisation
    optuna_search = OptunaSearchCV(
        estimator=pipeline,
        param_distributions=param_distributions,
        cv=cv,
        n_trials=n_trials,
        scoring=scoring,
        n_jobs=n_jobs,
        random_state=random_state,
        verbose=verbose
    )
    
    # Lancement de l'optimisation
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", message="X does not have valid feature names")
        optuna_search.fit(X_train, y_train)
    
    # Affichage des meilleurs rÃ©sultats
    print(f"ğŸ† Best {scoring} CV : {optuna_search.best_score_:.4f}")
    print("ğŸ”§ Best params:")
    for k, v in optuna_search.best_params_.items():
        print(f" - {k}: {v}")
    
    return optuna_search


def visualize_optuna_results(optuna_search: OptunaSearchCV) -> None:
    """
    Visualise les rÃ©sultats de l'optimisation Optuna.
    
    Args:
        optuna_search (OptunaSearchCV): Objet OptunaSearchCV ajustÃ©
        
    Raises:
        ImportError: Si optuna n'est pas installÃ©
    """
    if not HAS_OPTUNA:
        raise ImportError("Cette fonction nÃ©cessite optuna. "
                         "Installez-le avec 'pip install optuna'.")
    
    study = optuna_search.study_
    
    # Importance des hyperparamÃ¨tres
    param_importances = vis.plot_param_importances(study)
    param_importances.show()
    
    # Historique de l'optimisation
    optimization_history = vis.plot_optimization_history(study)
    optimization_history.show()
    
    # Diagramme de contours pour deux hyperparamÃ¨tres
    contour_plot = vis.plot_contour(study, params=['model__learning_rate', 'model__num_leaves'])
    contour_plot.show()
    
    # Diagramme de coordonnÃ©es parallÃ¨les
    parallel_coordinate = vis.plot_parallel_coordinate(study)
    parallel_coordinate.show()


################################################################################
####################### Ã‰VALUATION DES MODÃˆLES #################################
################################################################################

def evaluate_model(model: Any, 
                 X_train: pd.DataFrame, 
                 y_train: pd.Series,
                 X_test: pd.DataFrame, 
                 y_test: pd.Series) -> Dict[str, float]:
    """
    Ã‰value un modÃ¨le sur les donnÃ©es d'entraÃ®nement et de test.
    
    Args:
        model (Any): ModÃ¨le ajustÃ©
        X_train (pd.DataFrame): Features d'entraÃ®nement
        y_train (pd.Series): Cible d'entraÃ®nement
        X_test (pd.DataFrame): Features de test
        y_test (pd.Series): Cible de test
        
    Returns:
        Dict[str, float]: Dictionnaire des mÃ©triques d'Ã©valuation
    """
    # PrÃ©dictions
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    
    # Calcul des mÃ©triques
    r2_train = r2_score(y_train, y_train_pred)
    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))
    r2_test = r2_score(y_test, y_test_pred)
    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))
    
    # Ã‰cart RÂ²
    diff_r2 = r2_train - r2_test
    
    # Affichage des rÃ©sultats
    print("\nğŸ” VÃ©rification du surapprentissageâ€¦")
    print(f" - RÂ² train : {r2_train:.4f}")
    print(f" - RMSE train : {rmse_train:.2f}")
    
    print("\nğŸ“Š Ã‰valuation sur le jeu de test...")
    print(f" - RÂ² test : {r2_test:.4f}")
    print(f" - RMSE test : {rmse_test:.2f}")
    
    print(f"\nâ–¶ Ã‰cart RÂ² (train â€“ test) : {diff_r2:.4f}")
    if diff_r2 > 0.05:
        print("âš ï¸  Ã‰cart RÂ² > 0.05 : possible surapprentissage.")
    else:
        print("âœ… Ã‰cart RÂ² raisonnable, surapprentissage limitÃ©.")
    
    # Retour des mÃ©triques
    metrics = {
        "r2_train": r2_train,
        "rmse_train": rmse_train,
        "r2_test": r2_test,
        "rmse_test": rmse_test,
        "diff_r2": diff_r2
    }
    
    return metrics


def perform_stratified_cv(model: Any, 
                        X: pd.DataFrame, 
                        y: pd.Series,
                        n_splits: int = 5,
                        scoring: str = "r2",
                        random_state: int = 42) -> Tuple[np.ndarray, float, float]:
    """
    Effectue une validation croisÃ©e stratifiÃ©e sur un modÃ¨le.
    
    Args:
        model (Any): ModÃ¨le Ã  Ã©valuer
        X (pd.DataFrame): Features
        y (pd.Series): Cible
        n_splits (int): Nombre de folds
        scoring (str): MÃ©trique d'Ã©valuation
        random_state (int): Graine alÃ©atoire pour la reproductibilitÃ©
        
    Returns:
        Tuple[np.ndarray, float, float]: Scores par fold, score moyen, Ã©cart-type
    """
    # CrÃ©ation des bins pour la stratification
    y_strat = pd.qcut(y, q=n_splits, duplicates='drop', labels=False)
    
    # Configuration de la validation croisÃ©e
    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    
    # Calcul des scores
    cv_scores = cross_val_score(
        model,
        X,
        y,
        cv=cv.split(X, y_strat),
        scoring=scoring
    )
    
    # Calcul des statistiques
    mean_score = np.mean(cv_scores)
    std_score = np.std(cv_scores)
    
    # Affichage des rÃ©sultats
    print(f"Scores {scoring} par fold : {cv_scores}")
    print(f"Score {scoring} moyen (CV) : {mean_score:.4f} Â± {std_score:.4f}")
    
    return cv_scores, mean_score, std_score


################################################################################
####################### INTERPRÃ‰TATION DES MODÃˆLES #############################
################################################################################

def get_feature_names_from_column_transformer(column_transformer: Any) -> List[str]:
    """
    RÃ©cupÃ¨re les noms des features transformÃ©es Ã  partir d'un ColumnTransformer.
    
    Args:
        column_transformer (Any): ColumnTransformer ajustÃ©
        
    Returns:
        List[str]: Liste des noms de features transformÃ©es
    """
    feature_names = []
    
    for name, trans, cols in column_transformer.transformers_:
        if name != 'remainder':
            if hasattr(trans, 'get_feature_names_out'):
                try:
                    names = trans.get_feature_names_out()
                except TypeError:
                    names = trans.get_feature_names_out(cols)
                except:
                    names = cols
            elif hasattr(trans, 'named_steps'):
                last_step = list(trans.named_steps.values())[-1]
                if hasattr(last_step, 'get_feature_names_out'):
                    try:
                        names = last_step.get_feature_names_out(cols)
                    except:
                        names = cols
                else:
                    names = cols
            else:
                names = cols
            feature_names.extend(names)
        else:
            if trans == 'passthrough':
                feature_names.extend(cols)
    
    return feature_names


def calculate_shap_values(model: Any, 
                        X: pd.DataFrame, 
                        preproc: Optional[Any] = None,
                        sample_size: int = 500,
                        random_state: int = 42) -> Tuple[Any, np.ndarray, List[str]]:
    """
    Calcule les valeurs SHAP pour un modÃ¨le.
    
    Args:
        model (Any): ModÃ¨le ajustÃ©
        X (pd.DataFrame): Features
        preproc (Optional[Any]): PrÃ©processeur ajustÃ©
        sample_size (int): Taille de l'Ã©chantillon pour le calcul SHAP
        random_state (int): Graine alÃ©atoire pour la reproductibilitÃ©
        
    Returns:
        Tuple[Any, np.ndarray, List[str]]: Explainer SHAP, valeurs SHAP, noms des features
        
    Raises:
        ImportError: Si shap n'est pas installÃ©
    """
    if not HAS_SHAP:
        raise ImportError("Cette fonction nÃ©cessite shap. "
                         "Installez-le avec 'pip install shap'.")
    
    # SÃ©lection d'un sous-Ã©chantillon pour accÃ©lÃ©rer le calcul
    X_sample = X.sample(n=min(sample_size, len(X)), random_state=random_state)
    
    # Transformation des donnÃ©es si un prÃ©processeur est fourni
    if preproc is not None:
        X_transformed = preproc.transform(X_sample)
        feature_names = get_feature_names_from_column_transformer(preproc)
    else:
        X_transformed = X_sample
        feature_names = X_sample.columns.tolist()
    
    # Calcul des valeurs SHAP
    explainer = shap.Explainer(model)
    shap_values = explainer(X_transformed)
    
    return explainer, shap_values, feature_names


def plot_shap_summary(shap_values: Any, 
                    X_transformed: np.ndarray, 
                    feature_names: List[str]) -> None:
    """
    Affiche un rÃ©sumÃ© des valeurs SHAP.
    
    Args:
        shap_values (Any): Valeurs SHAP calculÃ©es
        X_transformed (np.ndarray): Features transformÃ©es
        feature_names (List[str]): Noms des features
        
    Raises:
        ImportError: Si shap n'est pas installÃ©
    """
    if not HAS_SHAP:
        raise ImportError("Cette fonction nÃ©cessite shap. "
                         "Installez-le avec 'pip install shap'.")
    
    shap.summary_plot(shap_values, X_transformed, feature_names=feature_names)


def select_top_features_by_shap(shap_values: Any, 
                              feature_names: List[str],
                              original_features: List[str],
                              top_n: int = 40) -> List[str]:
    """
    SÃ©lectionne les meilleures features selon leur importance SHAP.
    
    Args:
        shap_values (Any): Valeurs SHAP calculÃ©es
        feature_names (List[str]): Noms des features transformÃ©es
        original_features (List[str]): Noms des features originales
        top_n (int): Nombre de features Ã  sÃ©lectionner
        
    Returns:
        List[str]: Liste des meilleures features
        
    Raises:
        ImportError: Si shap n'est pas installÃ©
    """
    if not HAS_SHAP:
        raise ImportError("Cette fonction nÃ©cessite shap. "
                         "Installez-le avec 'pip install shap'.")
    
    # Calcul de l'importance SHAP
    shap_importance = np.abs(shap_values.values).mean(axis=0)
    
    # CrÃ©ation d'un DataFrame d'importance
    df_importance = pd.DataFrame({
        "feature": feature_names,
        "importance": shap_importance
    }).sort_values(by="importance", ascending=False)
    
    # Filtrage pour ne garder que les features mÃ©tiers
    features_metier = [f for f in original_features if f in df_importance["feature"].values]
    df_importance_metier = df_importance[df_importance["feature"].isin(features_metier)]
    
    # SÃ©lection des meilleures features
    top_features = df_importance_metier["feature"].head(top_n).tolist()
    
    print(f"Top {top_n} features mÃ©tiers : {top_features}")
    
    return top_features


################################################################################
####################### SAUVEGARDE ET CHARGEMENT ###############################
################################################################################

def save_model_and_features(model: Any, 
                          features: List[str],
                          model_path: str = "model.pkl",
                          features_path: str = "features.pkl") -> None:
    """
    Sauvegarde un modÃ¨le et sa liste de features.
    
    Args:
        model (Any): ModÃ¨le Ã  sauvegarder
        features (List[str]): Liste des features utilisÃ©es par le modÃ¨le
        model_path (str): Chemin de sauvegarde du modÃ¨le
        features_path (str): Chemin de sauvegarde des features
        
    Raises:
        ImportError: Si joblib n'est pas installÃ©
    """
    if not HAS_JOBLIB:
        raise ImportError("Cette fonction nÃ©cessite joblib. "
                         "Installez-le avec 'pip install joblib'.")
    
    # Sauvegarde du modÃ¨le et des features
    joblib.dump(model, model_path)
    joblib.dump(features, features_path)
    
    print(f"âœ… ModÃ¨le sauvegardÃ© dans {model_path}")
    print(f"âœ… Features sauvegardÃ©es dans {features_path}")
    
    # ContrÃ´le de cohÃ©rence
    loaded_features = joblib.load(features_path)
    assert features == loaded_features, "âŒ La liste des features sauvegardÃ©e ne correspond pas Ã  celle utilisÃ©e pour l'entraÃ®nement !"
    print("âœ… ContrÃ´le de cohÃ©rence : la liste des features est identique.")


def load_model_and_features(model_path: str = "model.pkl",
                          features_path: str = "features.pkl") -> Tuple[Any, List[str]]:
    """
    Charge un modÃ¨le et sa liste de features.
    
    Args:
        model_path (str): Chemin du modÃ¨le sauvegardÃ©
        features_path (str): Chemin des features sauvegardÃ©es
        
    Returns:
        Tuple[Any, List[str]]: ModÃ¨le chargÃ© et liste des features
        
    Raises:
        ImportError: Si joblib n'est pas installÃ©
        FileNotFoundError: Si les fichiers n'existent pas
    """
    if not HAS_JOBLIB:
        raise ImportError("Cette fonction nÃ©cessite joblib. "
                         "Installez-le avec 'pip install joblib'.")
    
    # VÃ©rification de l'existence des fichiers
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Le fichier modÃ¨le {model_path} n'existe pas.")
    if not os.path.exists(features_path):
        raise FileNotFoundError(f"Le fichier features {features_path} n'existe pas.")
    
    # Chargement du modÃ¨le et des features
    model = joblib.load(model_path)
    features = joblib.load(features_path)
    
    print(f"âœ… ModÃ¨le chargÃ© depuis {model_path}")
    print(f"âœ… Features chargÃ©es depuis {features_path} : {len(features)} features")
    
    return model, features


def make_prediction_example(model: Any, 
                          features: List[str],
                          X: pd.DataFrame,
                          index: int = 0) -> float:
    """
    Fait une prÃ©diction sur un exemple pour vÃ©rifier le fonctionnement du modÃ¨le.
    
    Args:
        model (Any): ModÃ¨le ajustÃ©
        features (List[str]): Liste des features utilisÃ©es par le modÃ¨le
        X (pd.DataFrame): DataFrame contenant les features
        index (int): Index de l'exemple Ã  utiliser
        
    Returns:
        float: Valeur prÃ©dite
    """
    # Extraction de l'exemple
    example_dict = {f: X.iloc[index][f] for f in features}
    X_input = pd.DataFrame([example_dict], columns=features)
    
    # PrÃ©diction
    y_pred = model.predict(X_input)
    
    print(f"PrÃ©diction pour l'exemple fourni : {y_pred[0]:.2f} â‚¬/mÂ²")
    
    return y_pred[0]


################################################################################
####################### SAUVEGARDE DES DONNÃ‰ES #################################
################################################################################

def save_dataframe(df: pd.DataFrame, 
                 file_path: str,
                 sep: str = ';',
                 index: bool = False,
                 verify: bool = True,
                 chunksize: int = 100000) -> Optional[pd.DataFrame]:
    """
    Sauvegarde un DataFrame et vÃ©rifie optionnellement le rÃ©sultat.
    
    Args:
        df (pd.DataFrame): DataFrame Ã  sauvegarder
        file_path (str): Chemin de sauvegarde
        sep (str): SÃ©parateur Ã  utiliser
        index (bool): Si True, sauvegarde l'index
        verify (bool): Si True, recharge et vÃ©rifie le DataFrame sauvegardÃ©
        chunksize (int): Taille des chunks pour la vÃ©rification
        
    Returns:
        Optional[pd.DataFrame]: DataFrame rechargÃ© si verify=True, None sinon
    """
    # Sauvegarde du DataFrame
    df.to_csv(file_path, sep=sep, index=index)
    print(f"âœ… DataFrame sauvegardÃ© dans {file_path}")
    
    # VÃ©rification optionnelle
    if verify:
        # Rechargement par chunks pour optimiser la mÃ©moire
        chunks = pd.read_csv(
            file_path, 
            sep=sep, 
            chunksize=chunksize, 
            index_col=None if not index else 0,
            on_bad_lines='skip', 
            low_memory=False
        )
        df_verify = pd.concat(chunk for chunk in chunks)
        
        # Affichage des informations
        print("\nVÃ©rification du DataFrame sauvegardÃ© :")
        print(df_verify.info())
        
        # Si le DataFrame contient une colonne cluster, afficher sa distribution
        if 'cluster' in df_verify.columns:
            print("\nValeurs uniques dans la colonne cluster :")
            print(df_verify['cluster'].value_counts())
        
        return df_verify
    
    return None


def save_train_test_data(X_train: pd.DataFrame, 
                       X_test: pd.DataFrame,
                       y_train: pd.Series,
                       y_test: pd.Series,
                       folder_path: str,
                       prefix: str = "",
                       sep: str = ';') -> None:
    """
    Sauvegarde les donnÃ©es d'entraÃ®nement et de test.
    
    Args:
        X_train (pd.DataFrame): Features d'entraÃ®nement
        X_test (pd.DataFrame): Features de test
        y_train (pd.Series): Cible d'entraÃ®nement
        y_test (pd.Series): Cible de test
        folder_path (str): Dossier de sauvegarde
        prefix (str): PrÃ©fixe pour les noms de fichiers
        sep (str): SÃ©parateur Ã  utiliser
    """
    # CrÃ©ation du dossier si nÃ©cessaire
    os.makedirs(folder_path, exist_ok=True)
    
    # Construction des chemins
    prefix = prefix + "_" if prefix else ""
    X_train_path = os.path.join(folder_path, f'{prefix}X_train.csv')
    X_test_path = os.path.join(folder_path, f'{prefix}X_test.csv')
    y_train_path = os.path.join(folder_path, f'{prefix}y_train.csv')
    y_test_path = os.path.join(folder_path, f'{prefix}y_test.csv')
    
    # Sauvegarde des donnÃ©es
    X_train.to_csv(X_train_path, sep=sep, index=False)
    X_test.to_csv(X_test_path, sep=sep, index=False)
    y_train.to_csv(y_train_path, sep=sep, index=False)
    y_test.to_csv(y_test_path, sep=sep, index=False)
    
    print(f"âœ… DonnÃ©es d'entraÃ®nement et de test sauvegardÃ©es dans {folder_path}")
    print(f" - X_train : {X_train.shape}")
    print(f" - X_test : {X_test.shape}")
    print(f" - y_train : {y_train.shape}")
    print(f" - y_test : {y_test.shape}")
