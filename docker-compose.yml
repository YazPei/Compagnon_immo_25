services:
# --------- Pipeline de lancement ----------
  run_full:
    build:
      context: .
      dockerfile: Dockerfile.run
    volumes:
      - .:/app

    tty: true
    stdin_open: true
    environment:
      - RUN_MODE=full
    depends_on:
      - mlflow
    networks:
      - ml_net


# --------- Préparation des données ----------

  fusion_geo:
    build:
      context: .
      dockerfile: Dockerfile.fusion
    volumes:
      - .:/app
      - ./mlops:/app/mlops
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - mlflow
    networks:
      - ml_net

  preprocessing:
    build:
      context: .
      dockerfile: Dockerfile.preprocessing
    image: compagnon_immo-preprocessing 
    volumes:
      - .:/app
      - ./data:/app/data
      - ./mlops/preprocessing:/app/mlops
    command: >
      python mlops/preprocessing/preprocessing.py
      --input-path /data
      --output-folder1 /app/data
      --output-folder2 /app/data
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - mlflow
    networks:
      - ml_net
      
  clustering:
    build:
      context: .
      dockerfile: Dockerfile.clustering
    volumes:
      - ./data:/app/data
      - ./mlops:/app/mlops
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - mlflow
    networks:
      - ml_net
    command: >
      python mlops/clustering/Clustering.py
      --input-path data/train_clean.csv
      --output-path1 data/df_cluster.csv
      --output-path2 data/df_sales_clean_ST.csv


  encode:
    build:
      context: .
      dockerfile: Dockerfile.encoding.REG
    volumes:
      - ./mlops/Regression:/app/mlops
      - ./data:/app/data
      - ./exports:/app/exports
    command: >
      python /app/mlops/encoding.py
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - mlflow
    networks:
      - ml_net
# --------- Régression ----------
  train_lgbm:
    build:
      context: .
      dockerfile: Dockerfile.lgbm.REG
    volumes:
      - ./mlops/Regression:/app/mlops
      - ./exports:/app/exports
    command: >
      python /app/mlops/train_lgbm.py
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      
    depends_on:
      - mlflow
    networks:
      - ml_net


  analyse:
    build:
      context: .
      dockerfile: Dockerfile.analyse.REG
    volumes:
      - ./mlops:/app/mlops
      - ./exports:/app/exports
    command: >
      python /app/mlops/Regression/analyse.py
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - mlflow
    networks:
      - ml_net

# --------- Séries Temporelles ----------
  split:
    build:
      context: .
      dockerfile: Dockerfile.split.ST
    volumes:
      - ./exports:/app/exports
      - ./data:/app/data
      - ./mlops:/app/mlops
    entrypoint: [ "python", "/app/mlops/Serie_temporelle/load_split.py" ]

    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - RUN_MODE=full
      - ST_SUFFIX=${ST_SUFFIX}
    depends_on:
      - mlflow
    networks:
      - ml_net

  decompose:
    build:
      context: .
      dockerfile: Dockerfile.decompose.ST
    volumes:
      - ./exports:/app/exports
      - ./mlops:/app/mlops
    command: >
      python /app/mlops/Serie_temporelle/seasonal_decomp.py
      --input-folder /app/exports/st
      --output-folder /app/exports/st
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - RUN_MODE=full
      - ST_SUFFIX=${ST_SUFFIX}
    depends_on:
      - mlflow
    networks:
      - ml_net

  train_sarimax:
    build:
      context: .
      dockerfile: Dockerfile.sarimax.ST
    volumes:
      - ./exports:/app/exports
      - ./mlops:/app/mlops
    command: >
      python /app/mlops/Serie_temporelle/sarimax_train.py
      --input-folder /app/exports/st
      --output-folder /app/exports/st
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - RUN_MODE=full
      - ST_SUFFIX=${ST_SUFFIX}
    depends_on:
      - mlflow
    networks:
      - ml_net
    
    
  evaluate:
    build:
      context: .
      dockerfile: Dockerfile.evaluate.ST
    volumes:
      - ./exports:/app/exports
      - ./mlops:/app/mlops
      - ./data:/app/data
    entrypoint: [ "python", "/app/mlops/Serie_temporelle/evaluate_ST.py" ]
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - RUN_MODE=full
      - ST_SUFFIX=${ST_SUFFIX}
    depends_on:
      - mlflow
    networks:
      - ml_net
          
  series_pipeline:
    build:
      context: .
      dockerfile: Dockerfile.series_pipeline
    volumes:
      - ./mlops:/app/mlops
      - ./data:/app/data
      - ./exports:/app/exports
    command: python /app/mlops/Serie_temporelle/pipeline.py --help
    networks:
      - ml_net


# --------- Tracking MLflow ----------
  mlflow:
    image: ghcr.io/mlflow/mlflow
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlflow/mlruns
    command: mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0
    networks:
      - ml_net
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000"]
      interval: 10s
      timeout: 5s
      retries: 3        

      
# --------- DVC ----------          

  dvc-runner:
    build:
      context: .
      dockerfile: mlops/2_dvc/Dockerfile.dvc
    volumes:
      - .:/app
      - ~/.dvc/config.local:/app/.dvc/config.local:ro
    working_dir: /app
    tty: true
    stdin_open: true
    command: sh
    depends_on:
      - mlflow
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000   
    networks:
      - ml_net

        
      
# --------- Scripts Factices ----------
  regression_script:
    image: busybox
    command: echo "Présence logique de regression/run_all.sh"


  st_script:
    image: busybox
    command: echo "Présence logique de Serie_temporelle/run_all_st.sh"
    
    


networks:
  ml_net:
    driver: bridge
