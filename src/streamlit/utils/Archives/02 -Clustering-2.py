import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from utils.Clustering import (
    regroup_cp,
    get_code_postal_final,
    prepare_data_for_clustering,
    calculate_tcam,
    aggregate_monthly_data,
    create_clustering_features,
    perform_clustering,
    apply_clustering_pipeline,
    determine_optimal_clusters,
    plot_cluster_evaluation,
    plot_cluster_distributions,
    plot_cluster_map
)

# Configuration
warnings.filterwarnings("ignore", category=RuntimeWarning)
warnings.filterwarnings("ignore", message="X does not have valid feature names")
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)

# Titre de la page
st.title("01.5 - Clustering des Donn√©es Immobili√®res")

# Param√®tres g√©n√©raux
RANDOM_STATE = 42
TARGET_VARIABLE = "prix_m2_vente"

# Chemin du fichier GeoJSON pour les codes postaux
geo_file_path = os.path.join(os.getcwd(), "data/geo/json/contours-codes-postaux.geojson")

# V√©rification de l'√©tat de session
if 'train_clean' not in st.session_state or 'test_clean' not in st.session_state:
    st.warning("‚ö†Ô∏è Vous devez d'abord ex√©cuter la page de pr√©traitement (01-Preprocessing) pour g√©n√©rer les donn√©es nettoy√©es.")
    st.stop()

# Sidebar pour les options
with st.sidebar:
    st.header("Options de Clustering")
    
    # Nombre de clusters
    n_clusters = st.slider(
        "Nombre de clusters :",
        min_value=2,
        max_value=10,
        value=4,
        step=1,
        help="Utilisez le curseur pour explorer l'impact du nombre de clusters sur la qualit√© de la segmentation"
    )
    
    # M√©thode de visualisation
    visualization_method = st.radio(
        "M√©thode de visualisation :",
        ["M√©thode du coude", "Score de silhouette", "Les deux"],
        index=2
    )
    
    # Bouton pour ex√©cuter le clustering
    run_clustering = st.button("Ex√©cuter le clustering")

# Corps principal
st.header("Introduction au Clustering")

st.write("""
Le clustering est une technique d'apprentissage non supervis√© qui permet de regrouper des donn√©es similaires en clusters (ou groupes). 
Dans le contexte de l'analyse immobili√®re, le clustering nous aide √† identifier des segments de march√© avec des caract√©ristiques similaires.

Nous utilisons l'algorithme K-means, qui partitionne les donn√©es en K clusters, chacun repr√©sent√© par la moyenne de ses points (centro√Øde).
""")

# Pr√©paration des donn√©es pour le clustering
if run_clustering or 'clustering_done' in st.session_state:
    with st.spinner("Pr√©paration des donn√©es pour le clustering..."):
        # R√©cup√©ration des donn√©es d'entra√Ænement et de test
        train_data = st.session_state.train_clean
        test_data = st.session_state.test_clean
        
        # Pr√©paration des donn√©es pour le clustering
        try:
            # √âtape 1: Regroupement des codes postaux
            st.subheader("1. Regroupement des codes postaux")
            
            # Exemple de regroupement de codes postaux
            sample_codes = ["75001", "13001", "97400", "inconnu"]
            regrouped_codes = [regroup_cp(code) for code in sample_codes]
            
            # Affichage des exemples de regroupement
            regrouped_df = pd.DataFrame({
                "Code postal original": sample_codes,
                "Code postal regroup√©": regrouped_codes
            })
            st.write("Exemples de regroupement de codes postaux :")
            st.dataframe(regrouped_df)
            
            st.write("""
            Le regroupement des codes postaux permet de r√©duire la granularit√© des donn√©es et d'obtenir des segments de march√© plus significatifs.
            - Les codes postaux standards sont regroup√©s par d√©partement (2 premiers chiffres)
            - Les codes postaux des DROM-COM (97xxx) sont regroup√©s par territoire (3 premiers chiffres)
            - Les codes postaux inconnus ou invalides sont regroup√©s dans la cat√©gorie "inconnu"
            """)
            
            # √âtape 2: Pr√©paration des donn√©es pour le clustering
            st.subheader("2. Pr√©paration des donn√©es pour le clustering")
            
            # Utilisation de la fonction prepare_data_for_clustering
            train_prepared = prepare_data_for_clustering(
                train_data,
                date_col="date",
                code_postal_col="codePostal" if "codePostal" in train_data.columns else "INSEE_COM",
                price_col=TARGET_VARIABLE
            )
            
            test_prepared = prepare_data_for_clustering(
                test_data,
                date_col="date",
                code_postal_col="codePostal" if "codePostal" in test_data.columns else "INSEE_COM",
                price_col=TARGET_VARIABLE
            )
            
            # Affichage des informations sur les donn√©es pr√©par√©es
            st.write(f"Donn√©es d'entra√Ænement pr√©par√©es : {train_prepared.shape[0]} lignes, {train_prepared.shape[1]} colonnes")
            st.write(f"Donn√©es de test pr√©par√©es : {test_prepared.shape[0]} lignes, {test_prepared.shape[1]} colonnes")
            
            # Affichage de la distribution des zones mixtes
            zone_counts = train_prepared["zone_mixte"].value_counts().head(10)
            
            fig, ax = plt.subplots(figsize=(10, 6))
            zone_counts.plot(kind="bar", ax=ax)
            ax.set_title("Top 10 des zones mixtes par nombre de biens")
            ax.set_xlabel("Zone mixte")
            ax.set_ylabel("Nombre de biens")
            st.pyplot(fig)
            
            # √âtape 3: Calcul du TCAM par zone
            st.subheader("3. Calcul du Taux de Croissance Annuel Moyen (TCAM) par zone")
            
            # Utilisation de la fonction calculate_tcam
            train_tcam = calculate_tcam(
                train_prepared,
                date_col="date",
                code_postal_col="zone_mixte",
                price_col=TARGET_VARIABLE
            )
            
            # Affichage des TCAM les plus √©lev√©s et les plus bas
            st.write("Zones avec les TCAM les plus √©lev√©s (croissance forte) :")
            st.dataframe(train_tcam.sort_values("tcam", ascending=False).head(5))
            
            st.write("Zones avec les TCAM les plus bas (croissance faible ou n√©gative) :")
            st.dataframe(train_tcam.sort_values("tcam").head(5))
            
            # Visualisation de la distribution des TCAM
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.histplot(train_tcam["tcam"].dropna(), kde=True, ax=ax)
            ax.set_title("Distribution des TCAM par zone")
            ax.set_xlabel("TCAM")
            ax.set_ylabel("Fr√©quence")
            st.pyplot(fig)
            
            # √âtape 4: Agr√©gation des donn√©es mensuelles
            st.subheader("4. Agr√©gation des donn√©es mensuelles par zone")
            
            # Utilisation de la fonction aggregate_monthly_data
            monthly_data = aggregate_monthly_data(
                train_prepared,
                date_col="date",
                code_postal_col="zone_mixte",
                price_col=TARGET_VARIABLE
            )
            
            # Affichage des donn√©es mensuelles agr√©g√©es
            st.write("Aper√ßu des donn√©es mensuelles agr√©g√©es :")
            st.dataframe(monthly_data.head())
            
            # Visualisation de l'√©volution des prix moyens pour quelques zones
            top_zones = train_tcam.sort_values("tcam", ascending=False).head(3)["zone_mixte"].tolist()
            
            fig, ax = plt.subplots(figsize=(12, 6))
            
            for zone in top_zones:
                zone_data = monthly_data[monthly_data["zone_mixte"] == zone]
                ax.plot(zone_data["date"], zone_data["prix_moyen"], label=f"Zone {zone}")
            
            ax.set_title("√âvolution des prix moyens pour les zones √† forte croissance")
            ax.set_xlabel("Date")
            ax.set_ylabel("Prix moyen (‚Ç¨/m¬≤)")
            ax.legend()
            st.pyplot(fig)
            
            # √âtape 5: Cr√©ation des features pour le clustering
            st.subheader("5. Cr√©ation des features pour le clustering")
            
            # Utilisation de la fonction create_clustering_features
            clustering_features = create_clustering_features(
                train_tcam,
                monthly_data,
                price_col="prix_moyen"
            )
            
            # Affichage des features de clustering
            st.write("Aper√ßu des features de clustering :")
            st.dataframe(clustering_features.head())
            
            # Visualisation des corr√©lations entre les features
            fig, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(
                clustering_features.drop(columns=["zone_mixte"]).corr(),
                annot=True,
                cmap="coolwarm",
                ax=ax
            )
            ax.set_title("Corr√©lations entre les features de clustering")
            st.pyplot(fig)
            
            # √âtape 6: D√©termination du nombre optimal de clusters
            st.subheader("6. D√©termination du nombre optimal de clusters")
            
            # Utilisation de la fonction determine_optimal_clusters
            inertia_values, silhouette_values = determine_optimal_clusters(
                clustering_features.drop(columns=["zone_mixte"]),
                max_clusters=10,
                random_state=RANDOM_STATE
            )
            
            # Stockage des r√©sultats dans la session
            st.session_state.inertia_values = inertia_values
            st.session_state.silhouette_values = silhouette_values
            
            # Affichage des r√©sultats
            if visualization_method in ["M√©thode du coude", "Les deux"]:
                st.write("### M√©thode du coude")
                st.write("""
                La m√©thode du coude est une technique utilis√©e pour d√©terminer le nombre optimal de clusters dans un algorithme de clustering. 
                Elle consiste √† tracer l'inertie (somme des distances au carr√© entre les points et le centre du cluster) en fonction du nombre de clusters 
                et √† identifier le point o√π l'ajout de nouveaux clusters n'am√©liore plus significativement l'inertie.
                """)
            
            if visualization_method in ["Score de silhouette", "Les deux"]:
                st.write("### Score de silhouette")
                st.write("""
                Le score de silhouette mesure la qualit√© des clusters en √©valuant √† quel point chaque point est similaire √† son propre cluster (coh√©sion) 
                par rapport aux autres clusters (s√©paration). Un score proche de 1 indique que les points sont bien regroup√©s dans leurs clusters respectifs.
                """)
            
            # Utilisation de la fonction plot_cluster_evaluation
            fig = plot_cluster_evaluation(
                inertia_values,
                silhouette_values,
                max_clusters=10
            )
            st.pyplot(fig)
            
            # √âtape 7: R√©alisation du clustering
            st.subheader("7. R√©alisation du clustering")
            
            # Utilisation de la fonction perform_clustering
            clusters, cluster_centers = perform_clustering(
                clustering_features.drop(columns=["zone_mixte"]),
                n_clusters=n_clusters,
                random_state=RANDOM_STATE
            )
            
            # Ajout des clusters aux features
            clustering_features["cluster"] = clusters
            
            # Affichage de la distribution des clusters
            st.write("Distribution des clusters :")
            cluster_counts = pd.Series(clusters).value_counts().sort_index()
            
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.barplot(x=cluster_counts.index, y=cluster_counts.values, ax=ax)
            ax.set_title(f"Distribution des {n_clusters} clusters")
            ax.set_xlabel("Cluster")
            ax.set_ylabel("Nombre de zones")
            st.pyplot(fig)
            
            # √âtape 8: Application du pipeline de clustering complet
            st.subheader("8. Application du pipeline de clustering complet")
            
            # Utilisation de la fonction apply_clustering_pipeline
            train_clustered, cluster_info = apply_clustering_pipeline(
                train_data, 
                n_clusters=n_clusters,
                date_col="date",
                code_postal_col="codePostal" if "codePostal" in train_data.columns else "INSEE_COM",
                price_col=TARGET_VARIABLE
            )
            
            # Ajout des clusters aux donn√©es de test
            zone_cluster_map = dict(zip(cluster_info["zone_mixte"], cluster_info["cluster"]))
            test_clustered = test_prepared.copy()
            test_clustered["cluster"] = test_clustered["zone_mixte"].map(zone_cluster_map)
            
            # Affichage des informations sur les donn√©es clusteris√©es
            st.write(f"Donn√©es d'entra√Ænement avec clusters : {train_clustered.shape[0]} lignes, {train_clustered.shape[1]} colonnes")
            st.write(f"Donn√©es de test avec clusters : {test_clustered.shape[0]} lignes, {test_clustered.shape[1]} colonnes")
            
            # Stockage des r√©sultats dans la session
            st.session_state.train_clustered = train_clustered
            st.session_state.test_clustered = test_clustered
            st.session_state.cluster_info = cluster_info
            st.session_state.clustering_done = True
            
            st.success("‚úÖ Clustering r√©alis√© avec succ√®s !")
        except Exception as e:
            st.error(f"‚ùå Erreur lors du clustering : {e}")
            st.stop()

# Affichage des r√©sultats du clustering
if 'clustering_done' in st.session_state:
    st.header("Analyse des r√©sultats du clustering")
    
    # Analyse des r√©sultats
    st.subheader("Interpr√©tation des m√©thodes d'√©valuation")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **M√©thode du Coude (courbe bleue)**
        - Point d'inflexion visible entre k=3 et k=5
        - Diminution rapide jusqu'√† 4-5 clusters
        - Stabilisation au-del√† de 5 clusters
        """)
    
    with col2:
        st.markdown("""
        **Score de Silhouette (courbe rouge)**
        - Score optimal g√©n√©ralement entre k=2 et k=4
        - Baisse progressive avec l'augmentation du nombre de clusters
        - Indique une meilleure s√©paration avec moins de clusters
        """)
    
    st.markdown("""
    **Recommandation:**
    - Pour une segmentation fine : 4-5 clusters
    - Pour une s√©paration optimale : 2-3 clusters
    - Compromis recommand√© : 4 clusters (√©quilibre entre pr√©cision et interpr√©tabilit√©)
    """)
    
    # Affichage des caract√©ristiques des clusters
    st.header("Caract√©ristiques des clusters")
    
    # Distribution des clusters
    st.subheader("Distribution des clusters")
    cluster_counts = st.session_state.train_clustered["cluster"].value_counts().sort_index()
    
    # Cr√©ation d'un DataFrame pour l'affichage
    cluster_distribution = pd.DataFrame({
        "Cluster": cluster_counts.index,
        "Nombre de biens": cluster_counts.values,
        "Pourcentage": (cluster_counts.values / cluster_counts.sum() * 100).round(2)
    })
    
    st.dataframe(cluster_distribution)
    
    # Visualisation de la distribution des clusters
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(x="Cluster", y="Nombre de biens", data=cluster_distribution, ax=ax)
    ax.set_title("Distribution des clusters")
    st.pyplot(fig)
    
    # Distribution des variables par cluster
    st.subheader("Distribution des variables par cluster")
    
    # Utilisation de la fonction plot_cluster_distributions
    cluster_figures = plot_cluster_distributions(
        st.session_state.train_clustered,
        cluster_col="cluster",
        price_col=TARGET_VARIABLE
    )
    
    # Affichage des figures
    for fig in cluster_figures:
        st.pyplot(fig)
    
    # R√©partition g√©ographique des clusters
    st.subheader("R√©partition g√©ographique des clusters")
    
    # V√©rification des colonnes n√©cessaires
    if all(col in st.session_state.train_clustered.columns for col in ['mapCoordonneesLatitude', 'mapCoordonneesLongitude', 'cluster']):
        # Utilisation de la fonction plot_cluster_map
        map_fig = plot_cluster_map(
            st.session_state.train_clustered,
            lat_col='mapCoordonneesLatitude',
            lon_col='mapCoordonneesLongitude',
            cluster_col='cluster'
        )
        st.pyplot(map_fig)
    else:
        st.warning("Les colonnes n√©cessaires pour la visualisation g√©ographique ne sont pas disponibles.")
    
    # Interpr√©tation des clusters
    st.header("Interpr√©tation des clusters")
    
    # Calcul des statistiques par cluster
    cluster_stats = st.session_state.train_clustered.groupby("cluster").agg({
        TARGET_VARIABLE: ["mean", "median", "std", "min", "max"],
        "surface": ["mean", "median"] if "surface" in st.session_state.train_clustered.columns else ["count"],
        "nb_pieces": ["mean", "median"] if "nb_pieces" in st.session_state.train_clustered.columns else ["count"]
    }).round(2)
    
    st.dataframe(cluster_stats)
    
    # Description des clusters
    st.subheader("Description des clusters")
    
    # Cr√©ation d'une description pour chaque cluster
    cluster_descriptions = {
        0: {
            "nom": "March√© √©conomique",
            "description": "Zones √† prix bas, faible volatilit√©, croissance mod√©r√©e. Typique des zones rurales ou peu dynamiques.",
            "caracteristiques": ["Prix les plus bas", "Faible dispersion", "Tr√®s faible volatilit√©", "Croissance faible ou stable"]
        },
        1: {
            "nom": "March√© interm√©diaire",
            "description": "Zones √† prix moyens, volatilit√© mod√©r√©e, croissance stable. Repr√©sentatif des zones p√©riurbaines.",
            "caracteristiques": ["Prix moyens", "Dispersion moyenne", "Volatilit√© mod√©r√©e", "Croissance mod√©r√©e"]
        },
        2: {
            "nom": "March√© dynamique",
            "description": "Zones √† prix moyens-hauts, bonne dynamique, croissance soutenue. Caract√©ristique des centres urbains √©tablis.",
            "caracteristiques": ["Prix moyens √† moyens-hauts", "Dispersion mod√©r√©e", "Stabilit√© relative", "Croissance r√©guli√®re"]
        },
        3: {
            "nom": "March√© premium",
            "description": "Zones √† prix √©lev√©s, forte volatilit√©, croissance forte. Typique des zones urbaines premium ou touristiques.",
            "caracteristiques": ["Prix les plus √©lev√©s", "Grande dispersion", "Forte volatilit√©", "Croissance soutenue"]
        }
    }
    
    # Affichage des descriptions
    for cluster_id in range(min(n_clusters, 4)):
        if cluster_id in cluster_descriptions:
            st.write(f"**Cluster {cluster_id} - {cluster_descriptions[cluster_id]['nom']}**")
            st.write(cluster_descriptions[cluster_id]['description'])
            st.write("Caract√©ristiques principales :")
            for carac in cluster_descriptions[cluster_id]['caracteristiques']:
                st.write(f"- {carac}")
            st.write("---")
    
    # Conclusion
    st.header("Conclusion")
    
    st.write("""
    L'analyse par clustering nous a permis d'identifier des segments distincts du march√© immobilier fran√ßais, 
    chacun avec ses propres caract√©ristiques en termes de prix, volatilit√© et dynamique de croissance.
    
    Cette segmentation offre une vision claire des diff√©rentes dynamiques du march√©, avec des profils de risque 
    et de rendement bien diff√©renci√©s, ce qui peut guider les strat√©gies d'investissement et les politiques publiques.
    
    Dans la prochaine √©tape (R√©gression), nous utiliserons ces clusters comme variables explicatives pour am√©liorer 
    la pr√©cision de nos mod√®les de pr√©diction des prix immobiliers.
    """)
    
    # Sauvegarde des donn√©es pour la page suivante
    st.session_state.train_data_for_regression = st.session_state.train_clustered
    st.session_state.test_data_for_regression = st.session_state.test_clustered
else:
    st.info("üëà Utilisez les options dans la barre lat√©rale pour configurer et ex√©cuter le clustering.")
