{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6acf2f",
   "metadata": {},
   "source": [
    "# Série Temporelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83fc029",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Ce notebook se concentre sur l'analyse des séries temporelles des prix immobiliers. Il utilise les données prétraitées par le notebook Part-1 bis qui centralise le clustering et la préparation des données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587fe98",
   "metadata": {},
   "source": [
    "## 1. Imports et configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter magic\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit, prange\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Geospatial imports\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Configuration de l'affichage pandas\n",
    "pd.set_option('display.max_columns', None)  # Affiche toutes les colonnes\n",
    "pd.set_option('display.width', 1000)       # Ajuste la largeur pour éviter les coupures\n",
    "pd.set_option('display.colheader_justify', 'center')  # Centre les noms des colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87927d14",
   "metadata": {},
   "source": [
    "## 2. Configuration des chemins d'accès\n",
    "\n",
    "Décommentez le chemin correspondant à votre environnement ou ajoutez le vôtre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ac171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des chemins d'accès aux données\n",
    "# Décommentez le chemin correspondant à votre environnement\n",
    "\n",
    "# folder_path_M = '/Users/maximehenon/Documents/GitHub/MAR25_BDS_Compagnon_Immo/'\n",
    "folder_path_Y = \"C:/Users/charl/OneDrive/Documents/Yasmine/DATASCIENTEST/FEV25-BDS-COMPAGNON\"\n",
    "# folder_path_C = '../data/processed/Sales'\n",
    "# folder_path_L = '/Users/loick.d/Documents/Datascientest/Github immo/MAR25_BDS_Compagnon_Immo/'\n",
    "# folder_path_LW = 'C:/Users/User/Downloads/drive-download-20250508T155351Z-1-001'\n",
    "\n",
    "# Utilisez cette variable pour définir votre chemin\n",
    "folder_path = folder_path_Y  # Remplacez par votre variable de chemin\n",
    "\n",
    "# Chemins des fichiers préparés par Part-1 bis\n",
    "train_cluster_file = os.path.join(folder_path, 'train_cluster_prepared.csv')\n",
    "train_mensuel_file = os.path.join(folder_path, 'train_mensuel_prepared.csv')\n",
    "geo_file_name = 'contours-codes-postaux.geojson'\n",
    "geo_file = os.path.join(folder_path, geo_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d681f4fb-header",
   "metadata": {},
   "source": [
    "## 3. Chargement des données\n",
    "\n",
    "Nous chargeons ici les données prétraitées par le notebook Part-1 bis, qui a déjà effectué :\n",
    "- Le chargement des données brutes\n",
    "- Le split des données\n",
    "- L'agrégation mensuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d681f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prepared_data(file_path, index_col='date', parse_dates=True):\n",
    "    \"\"\"Charge les données préparées par Part-1 bis.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Chemin du fichier CSV\n",
    "        index_col (str): Colonne à utiliser comme index\n",
    "        parse_dates (bool): Si True, parse les dates\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Données chargées\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"⏳ Chargement des données depuis {file_path}\")\n",
    "        df = pd.read_csv(\n",
    "            file_path,\n",
    "            sep=\";\",\n",
    "            index_col=index_col if index_col else None,\n",
    "            parse_dates=True if parse_dates and index_col else None,\n",
    "            low_memory=False\n",
    "        )\n",
    "        print(f\"✅ Données chargées avec succès : {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du chargement des données : {e}\")\n",
    "        raise\n",
    "\n",
    "# Chargement des données préparées\n",
    "df_sales_clean_ST = load_prepared_data(train_cluster_file, index_col=None)\n",
    "\n",
    "# Affichage des informations sur le dataset\n",
    "print(\"\\nAperçu des données:\")\n",
    "display(df_sales_clean_ST.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geo-processing-header",
   "metadata": {},
   "source": [
    "## 4. Enrichissement géospatial\n",
    "\n",
    "Nous enrichissons les données avec les codes postaux en utilisant les coordonnées géographiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geo-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des polygones de codes postaux\n",
    "pcodes = gpd.read_file(geo_file)[['codePostal', 'geometry']]\n",
    "print(\"Polygones chargés :\", pcodes.shape)\n",
    "\n",
    "# Prétraitement géo\n",
    "df_base = df_sales_clean_ST.copy()\n",
    "df_base = df_base.dropna(subset=['mapCoordonneesLatitude', 'mapCoordonneesLongitude'])\n",
    "df_base['lat'] = df_base['mapCoordonneesLatitude']\n",
    "df_base['lon'] = df_base['mapCoordonneesLongitude']\n",
    "df_base['orig_index'] = df_base.index\n",
    "\n",
    "# Fonction de traitement spatial d'un chunk\n",
    "def process_chunk(chunk, pcodes):\n",
    "    chunk = chunk.copy()\n",
    "    chunk['geometry'] = gpd.points_from_xy(chunk['lon'], chunk['lat'])\n",
    "    gdf = gpd.GeoDataFrame(chunk, geometry='geometry', crs='EPSG:4326')\n",
    "    joined = gpd.sjoin(gdf, pcodes, how='left', predicate='within')\n",
    "    return joined[['orig_index', 'codePostal']]  # retour minimal\n",
    "\n",
    "# Traitement par chunks pour limiter la mémoire\n",
    "chunksize = 100_000\n",
    "results = []\n",
    "\n",
    "for i in range(0, len(df_base), chunksize):\n",
    "    chunk = df_base.iloc[i:i+chunksize]\n",
    "    result = process_chunk(chunk, pcodes)\n",
    "    results.append(result)\n",
    "\n",
    "# Concaténation des résultats et merge final\n",
    "df_joined = pd.concat(results, ignore_index=True).drop_duplicates(\"orig_index\")\n",
    "df_sales_clean_ST['orig_index'] = df_sales_clean_ST.index  # pour merge\n",
    "df_sales_clean_ST = df_sales_clean_ST.merge(df_joined[['orig_index', 'codePostal']], on=\"orig_index\", how=\"left\")\n",
    "df_sales_clean_ST.drop(columns=['orig_index'], inplace=True)\n",
    "\n",
    "# Vérification du résultat\n",
    "print(df_sales_clean_ST[['mapCoordonneesLatitude', 'mapCoordonneesLongitude', 'codePostal', 'date']].head())\n",
    "print(\"Code postal manquant :\", df_sales_clean_ST['codePostal'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "date-formatting-header",
   "metadata": {},
   "source": [
    "## 5. Préparation des données temporelles\n",
    "\n",
    "Nous préparons les données pour l'analyse temporelle en formatant les dates et en créant des variables d'année et de mois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "date-formatting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de la colonne date en datetime\n",
    "df_sales_clean_ST['date'] = pd.to_datetime(df_sales_clean_ST['date'], errors='coerce')\n",
    "df_sales_clean_ST = df_sales_clean_ST.sort_values('date')\n",
    "\n",
    "# Définir la colonne 'date' comme index\n",
    "df_sales_clean_ST = df_sales_clean_ST.set_index('date')\n",
    "\n",
    "# Création des variables année et mois et traitement du codePostal\n",
    "df_sales_clean_ST[\"Year\"] = df_sales_clean_ST.index.year\n",
    "df_sales_clean_ST[\"Month\"] = df_sales_clean_ST.index.month\n",
    "\n",
    "# Conversion du code postal en string et nettoyage\n",
    "df_sales_clean_ST[\"codePostal\"] = df_sales_clean_ST[\"codePostal\"].astype(str).str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "\n",
    "# Vérification des colonnes datetime\n",
    "datetime_cols = df_sales_clean_ST.select_dtypes(include=[\"datetime64[ns]\"]).columns\n",
    "for col in datetime_cols:\n",
    "    print(f\"Colonne datetime : {col}\")\n",
    "    print(df_sales_clean_ST[col].unique())\n",
    "\n",
    "# Affichage des données formatées\n",
    "display(df_sales_clean_ST.head())\n",
    "display(df_sales_clean_ST[\"codePostal\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregation-header",
   "metadata": {},
   "source": [
    "## 6. Agrégation mensuelle\n",
    "\n",
    "Nous agrégeons les données par mois pour l'analyse des séries temporelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrégation nationale par mois\n",
    "train_mensuel = (\n",
    "    df_sales_clean_ST\n",
    "    .groupby([\"Year\", \"Month\"])\n",
    "    .agg(\n",
    "        prix_m2_vente_mean=(\"prix_m2_vente\", \"mean\"),\n",
    "        prix_m2_vente_median=(\"prix_m2_vente\", \"median\"),\n",
    "        prix_m2_vente_std=(\"prix_m2_vente\", \"std\"),\n",
    "        prix_m2_vente_min=(\"prix_m2_vente\", \"min\"),\n",
    "        prix_m2_vente_max=(\"prix_m2_vente\", \"max\"),\n",
    "        prix_m2_vente_count=(\"prix_m2_vente\", \"count\"),\n",
    "        nb_transactions=(\"prix_m2_vente\", \"count\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Formattage des données temporelles\n",
    "train_mensuel[\"date\"] = pd.to_datetime(\n",
    "    train_mensuel[\"Year\"].astype(str) + \"-\" + train_mensuel[\"Month\"].astype(str) + \"-01\"\n",
    ")\n",
    "\n",
    "# Affichage des données agrégées\n",
    "display(train_mensuel.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dept-aggregation-header",
   "metadata": {},
   "source": [
    "## 7. Agrégation par département\n",
    "\n",
    "Nous agrégeons également les données par département pour analyser les différences régionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dept-aggregation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction du département à partir du code postal\n",
    "df_sales_clean_ST['departement'] = df_sales_clean_ST['codePostal'].str[:2]\n",
    "\n",
    "# Correction pour les départements corses\n",
    "df_sales_clean_ST.loc[df_sales_clean_ST['codePostal'].str.startswith('20'), 'departement'] = df_sales_clean_ST.loc[df_sales_clean_ST['codePostal'].str.startswith('20'), 'codePostal'].apply(\n",
    "    lambda x: '2A' if x >= '20000' and x <= '20190' else '2B'\n",
    ")\n",
    "\n",
    "# Agrégation par département et par mois\n",
    "dept_mensuel = (\n",
    "    df_sales_clean_ST\n",
    "    .groupby([\"Year\", \"Month\", \"departement\"])\n",
    "    .agg(\n",
    "        prix_m2_vente_mean=(\"prix_m2_vente\", \"mean\"),\n",
    "        prix_m2_vente_median=(\"prix_m2_vente\", \"median\"),\n",
    "        prix_m2_vente_std=(\"prix_m2_vente\", \"std\"),\n",
    "        nb_transactions=(\"prix_m2_vente\", \"count\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Formattage des dates\n",
    "dept_mensuel[\"date\"] = pd.to_datetime(\n",
    "    dept_mensuel[\"Year\"].astype(str) + \"-\" + dept_mensuel[\"Month\"].astype(str) + \"-01\"\n",
    ")\n",
    "\n",
    "# Affichage des données agrégées par département\n",
    "display(dept_mensuel.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paris-analysis-header",
   "metadata": {},
   "source": [
    "## 8. Analyse spécifique de Paris\n",
    "\n",
    "Nous analysons en détail le marché immobilier parisien, qui présente des caractéristiques particulières."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paris-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrage des données pour Paris (75)\n",
    "paris_data = df_sales_clean_ST.reset_index()\n",
    "paris_data = paris_data[paris_data['codePostal'].str.startswith('75', na=False)]\n",
    "\n",
    "# Extraction de l'arrondissement\n",
    "paris_data['arrondissement'] = paris_data['codePostal'].str[2:].astype(int)\n",
    "\n",
    "# Affichage des premières lignes pour Paris\n",
    "display(paris_data.head())\n",
    "\n",
    "# Agrégation par arrondissement et par mois\n",
    "paris_mensuel = (\n",
    "    paris_data\n",
    "    .groupby([\"Year\", \"Month\", \"arrondissement\"])\n",
    "    .agg(\n",
    "        prix_m2_vente_mean=(\"prix_m2_vente\", \"mean\"),\n",
    "        nb_transactions=(\"prix_m2_vente\", \"count\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Formattage des dates\n",
    "paris_mensuel[\"date\"] = pd.to_datetime(\n",
    "    paris_mensuel[\"Year\"].astype(str) + \"-\" + paris_mensuel[\"Month\"].astype(str) + \"-01\"\n",
    ")\n",
    "\n",
    "# Visualisation des prix par arrondissement\n",
    "fig = px.line(\n",
    "    paris_mensuel, \n",
    "    x=\"date\", \n",
    "    y=\"prix_m2_vente_mean\", \n",
    "    color=\"arrondissement\",\n",
    "    title=\"Évolution du prix moyen au m² par arrondissement de Paris\",\n",
    "    labels={\"date\": \"Date\", \"prix_m2_vente_mean\": \"Prix moyen (€ / m²)\", \"arrondissement\": \"Arrondissement\"}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17bb4fa-header",
   "metadata": {},
   "source": [
    "## 9. Visualisation des tendances temporelles nationales\n",
    "\n",
    "Nous visualisons l'évolution des prix et du nombre de transactions au niveau national."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17bb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'évolution du prix moyen au m²\n",
    "fig = px.line(\n",
    "    train_mensuel, \n",
    "    x=\"date\", \n",
    "    y=\"prix_m2_vente_mean\",\n",
    "    title=\"Évolution du prix moyen au m² en France\",\n",
    "    labels={\"date\": \"Date\", \"prix_m2_vente_mean\": \"Prix moyen (€ / m²)\"}\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Visualisation du nombre de transactions\n",
    "fig = px.line(\n",
    "    train_mensuel, \n",
    "    x=\"date\", \n",
    "    y=\"nb_transactions\",\n",
    "    title=\"Évolution du nombre de transactions immobilières en France\",\n",
    "    labels={\"date\": \"Date\", \"nb_transactions\": \"Nombre de transactions\"}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departement-analysis-header",
   "metadata": {},
   "source": [
    "## 10. Analyse des tendances par département\n",
    "\n",
    "Nous comparons l'évolution des prix et des transactions entre les principaux départements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departement-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des départements avec le plus de transactions\n",
    "top_depts = dept_mensuel.groupby(\"departement\")[\"nb_transactions\"].sum().nlargest(10).index.tolist()\n",
    "print(f\"Top 10 départements par nombre de transactions : {top_depts}\")\n",
    "\n",
    "# Filtrage des données pour ces départements\n",
    "top_dept_data = dept_mensuel[dept_mensuel[\"departement\"].isin(top_depts)]\n",
    "\n",
    "# Visualisation des prix par département\n",
    "fig = px.line(\n",
    "    top_dept_data, \n",
    "    x=\"date\", \n",
    "    y=\"prix_m2_vente_mean\", \n",
    "    color=\"departement\",\n",
    "    title=\"Évolution du prix moyen au m² par département\",\n",
    "    labels={\"date\": \"Date\", \"prix_m2_vente_mean\": \"Prix moyen (€ / m²)\", \"departement\": \"Département\"}\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Visualisation du nombre de transactions par département\n",
    "fig = px.line(\n",
    "    top_dept_data, \n",
    "    x=\"date\", \n",
    "    y=\"nb_transactions\", \n",
    "    color=\"departement\",\n",
    "    title=\"Évolution du nombre de transactions par département\",\n",
    "    labels={\"date\": \"Date\", \"nb_transactions\": \"Nombre de transactions\", \"departement\": \"Département\"}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-analysis-header",
   "metadata": {},
   "source": [
    "## 11. Analyse de la saisonnalité\n",
    "\n",
    "Nous examinons les tendances saisonnières dans les prix et le volume des transactions immobilières."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrégation par mois (tous les ans confondus)\n",
    "monthly_agg = train_mensuel.groupby('Month').agg(\n",
    "    prix_m2_vente_mean=('prix_m2_vente_mean', 'mean'),\n",
    "    nb_transactions=('nb_transactions', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Ajout des noms des mois\n",
    "month_names = ['Janvier', 'Février', 'Mars', 'Avril', 'Mai', 'Juin', 'Juillet', 'Août', 'Septembre', 'Octobre', 'Novembre', 'Décembre']\n",
    "monthly_agg['month_name'] = monthly_agg['Month'].apply(lambda x: month_names[x-1])\n",
    "\n",
    "# Visualisation de la saisonnalité des prix\n",
    "fig = px.bar(\n",
    "    monthly_agg, \n",
    "    x='month_name', \n",
    "    y='prix_m2_vente_mean',\n",
    "    title=\"Prix moyen au m² par mois (saisonnalité)\",\n",
    "    labels={'month_name': 'Mois', 'prix_m2_vente_mean': 'Prix moyen (€ / m²)'}\n",
    ")\n",
    "fig.update_xaxes(categoryorder='array', categoryarray=month_names)\n",
    "fig.show()\n",
    "\n",
    "# Visualisation de la saisonnalité des transactions\n",
    "fig = px.bar(\n",
    "    monthly_agg, \n",
    "    x='month_name', \n",
    "    y='nb_transactions',\n",
    "    title=\"Nombre moyen de transactions par mois (saisonnalité)\",\n",
    "    labels={'month_name': 'Mois', 'nb_transactions': 'Nombre moyen de transactions'}\n",
    ")\n",
    "fig.update_xaxes(categoryorder='array', categoryarray=month_names)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trend-analysis-header",
   "metadata": {},
   "source": [
    "## 12. Décomposition des séries temporelles\n",
    "\n",
    "Nous décomposons les séries temporelles pour identifier les tendances, la saisonnalité et les résidus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trend-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Préparation des données pour la décomposition\n",
    "ts_data = train_mensuel.set_index('date')['prix_m2_vente_mean']\n",
    "\n",
    "# Décomposition de la série temporelle\n",
    "decomposition = seasonal_decompose(ts_data, model='additive', period=12)\n",
    "\n",
    "# Création d'une figure avec 4 sous-graphiques\n",
    "fig = make_subplots(rows=4, cols=1, subplot_titles=('Série originale', 'Tendance', 'Saisonnalité', 'Résidus'))\n",
    "\n",
    "# Ajout des composantes à la figure\n",
    "fig.add_trace(go.Scatter(x=ts_data.index, y=ts_data.values, mode='lines', name='Original'), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts_data.index, y=decomposition.trend, mode='lines', name='Tendance'), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts_data.index, y=decomposition.seasonal, mode='lines', name='Saisonnalité'), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts_data.index, y=decomposition.resid, mode='lines', name='Résidus'), row=4, col=1)\n",
    "\n",
    "# Mise en forme de la figure\n",
    "fig.update_layout(height=900, title_text=\"Décomposition de la série temporelle des prix immobiliers\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forecast-header",
   "metadata": {},
   "source": [
    "## 13. Modélisation et prévision\n",
    "\n",
    "Nous utilisons des modèles de séries temporelles pour prévoir l'évolution future des prix immobiliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forecast-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Préparation des données\n",
    "ts_data = train_mensuel.set_index('date')['prix_m2_vente_mean']\n",
    "\n",
    "# Split train/test\n",
    "train_size = int(len(ts_data) * 0.8)\n",
    "train_ts = ts_data[:train_size]\n",
    "test_ts = ts_data[train_size:]\n",
    "\n",
    "# Modèle ARIMA\n",
    "model = ARIMA(train_ts, order=(1, 1, 1))\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())\n",
    "\n",
    "# Prévisions\n",
    "forecast = model_fit.forecast(steps=len(test_ts))\n",
    "\n",
    "# Évaluation\n",
    "mse = mean_squared_error(test_ts, forecast)\n",
    "mae = mean_absolute_error(test_ts, forecast)\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "\n",
    "# Visualisation des prévisions\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=train_ts.index, y=train_ts.values, mode='lines', name='Données d\\'entraînement'))\n",
    "fig.add_trace(go.Scatter(x=test_ts.index, y=test_ts.values, mode='lines', name='Données de test'))\n",
    "fig.add_trace(go.Scatter(x=test_ts.index, y=forecast, mode='lines', name='Prévisions ARIMA'))\n",
    "fig.update_layout(title='Prévisions ARIMA des prix immobiliers', xaxis_title='Date', yaxis_title='Prix moyen (€ / m²)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sarima-header",
   "metadata": {},
   "source": [
    "## 14. Modèle SARIMA pour la saisonnalité\n",
    "\n",
    "Nous utilisons un modèle SARIMA pour capturer la saisonnalité dans les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sarima-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle SARIMA (ARIMA saisonnier)\n",
    "sarima_model = SARIMAX(train_ts, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "sarima_fit = sarima_model.fit(disp=False)\n",
    "print(sarima_fit.summary())\n",
    "\n",
    "# Prévisions SARIMA\n",
    "sarima_forecast = sarima_fit.forecast(steps=len(test_ts))\n",
    "\n",
    "# Évaluation SARIMA\n",
    "sarima_mse = mean_squared_error(test_ts, sarima_forecast)\n",
    "sarima_mae = mean_absolute_error(test_ts, sarima_forecast)\n",
    "print(f\"SARIMA MSE: {sarima_mse:.2f}\")\n",
    "print(f\"SARIMA MAE: {sarima_mae:.2f}\")\n",
    "\n",
    "# Comparaison des performances\n",
    "print(f\"Amélioration MSE: {(mse - sarima_mse) / mse * 100:.2f}%\")\n",
    "print(f\"Amélioration MAE: {(mae - sarima_mae) / mae * 100:.2f}%\")\n",
    "\n",
    "# Visualisation des prévisions SARIMA\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=train_ts.index, y=train_ts.values, mode='lines', name='Données d\\'entraînement'))\n",
    "fig.add_trace(go.Scatter(x=test_ts.index, y=test_ts.values, mode='lines', name='Données de test'))\n",
    "fig.add_trace(go.Scatter(x=test_ts.index, y=sarima_forecast, mode='lines', name='Prévisions SARIMA'))\n",
    "fig.update_layout(title='Prévisions SARIMA des prix immobiliers', xaxis_title='Date', yaxis_title='Prix moyen (€ / m²)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-forecast-header",
   "metadata": {},
   "source": [
    "## 15. Prévisions futures\n",
    "\n",
    "Nous utilisons le meilleur modèle pour faire des prévisions sur les 12 prochains mois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-forecast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle sur toutes les données\n",
    "full_model = SARIMAX(ts_data, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "full_model_fit = full_model.fit(disp=False)\n",
    "\n",
    "# Prévisions pour les 12 prochains mois\n",
    "future_steps = 12\n",
    "future_forecast = full_model_fit.forecast(steps=future_steps)\n",
    "\n",
    "# Création des dates futures\n",
    "last_date = ts_data.index[-1]\n",
    "future_dates = pd.date_range(start=last_date + pd.DateOffset(months=1), periods=future_steps, freq='MS')\n",
    "\n",
    "# Visualisation des prévisions futures\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ts_data.index, y=ts_data.values, mode='lines', name='Données historiques'))\n",
    "fig.add_trace(go.Scatter(x=future_dates, y=future_forecast, mode='lines', name='Prévisions futures', line=dict(dash='dash')))\n",
    "fig.update_layout(\n",
    "    title='Prévisions des prix immobiliers pour les 12 prochains mois',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Prix moyen (€ / m²)',\n",
    "    shapes=[\n",
    "        dict(\n",
    "            type=\"rect\",\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            x0=last_date,\n",
    "            y0=0,\n",
    "            x1=future_dates[-1],\n",
    "            y1=1,\n",
    "            fillcolor=\"lightgray\",\n",
    "            opacity=0.2,\n",
    "            layer=\"below\",\n",
    "            line_width=0,\n",
    "        )\n",
    "    ],\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=last_date + (future_dates[-1] - last_date)/2,\n",
    "            y=1.05,\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            text=\"Période de prévision\",\n",
    "            showarrow=False,\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cluster-analysis-header",
   "metadata": {},
   "source": [
    "## 16. Analyse par cluster\n",
    "\n",
    "Nous analysons l'évolution des prix immobiliers par cluster pour identifier les différences entre les types de zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cluster-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la présence de la colonne cluster\n",
    "if 'cluster' in df_sales_clean_ST.columns or 'cluster_label' in df_sales_clean_ST.columns:\n",
    "    # Détermination du nom de la colonne cluster\n",
    "    cluster_col = 'cluster' if 'cluster' in df_sales_clean_ST.columns else 'cluster_label'\n",
    "    \n",
    "    # Agrégation par cluster et par mois\n",
    "    cluster_mensuel = (\n",
    "        df_sales_clean_ST\n",
    "        .groupby([\"Year\", \"Month\", cluster_col])\n",
    "        .agg(\n",
    "            prix_m2_vente_mean=(\"prix_m2_vente\", \"mean\"),\n",
    "            nb_transactions=(\"prix_m2_vente\", \"count\")\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Formattage des dates\n",
    "    cluster_mensuel[\"date\"] = pd.to_datetime(\n",
    "        cluster_mensuel[\"Year\"].astype(str) + \"-\" + cluster_mensuel[\"Month\"].astype(str) + \"-01\"\n",
    "    )\n",
    "    \n",
    "    # Visualisation des prix par cluster\n",
    "    fig = px.line(\n",
    "        cluster_mensuel, \n",
    "        x=\"date\", \n",
    "        y=\"prix_m2_vente_mean\", \n",
    "        color=cluster_col,\n",
    "        title=\"Évolution du prix moyen au m² par cluster\",\n",
    "        labels={\"date\": \"Date\", \"prix_m2_vente_mean\": \"Prix moyen (€ / m²)\", cluster_col: \"Cluster\"}\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Visualisation du nombre de transactions par cluster\n",
    "    fig = px.line(\n",
    "        cluster_mensuel, \n",
    "        x=\"date\", \n",
    "        y=\"nb_transactions\", \n",
    "        color=cluster_col,\n",
    "        title=\"Évolution du nombre de transactions par cluster\",\n",
    "        labels={\"date\": \"Date\", \"nb_transactions\": \"Nombre de transactions\", cluster_col: \"Cluster\"}\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"Aucune colonne de cluster n'a été trouvée dans les données.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "## 17. Export des données préparées\n",
    "\n",
    "Nous exportons les données agrégées pour une utilisation ultérieure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export des données mensuelles nationales\n",
    "train_mensuel.to_csv(os.path.join(folder_path, 'train_mensuel_analysis.csv'), sep=';', index=False)\n",
    "print(f\"Données mensuelles nationales exportées vers {os.path.join(folder_path, 'train_mensuel_analysis.csv')}\")\n",
    "\n",
    "# Export des données mensuelles par département\n",
    "dept_mensuel.to_csv(os.path.join(folder_path, 'dept_mensuel_analysis.csv'), sep=';', index=False)\n",
    "print(f\"Données mensuelles par département exportées vers {os.path.join(folder_path, 'dept_mensuel_analysis.csv')}\")\n",
    "\n",
    "# Export des prévisions\n",
    "forecast_df = pd.DataFrame({\n",
    "    'date': future_dates,\n",
    "    'prix_m2_vente_forecast': future_forecast\n",
    "})\n",
    "forecast_df.to_csv(os.path.join(folder_path, 'prix_forecast.csv'), sep=';', index=False)\n",
    "print(f\"Prévisions exportées vers {os.path.join(folder_path, 'prix_forecast.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-header",
   "metadata": {},
   "source": [
    "## 18. Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons analysé les séries temporelles des prix immobiliers en France. Nous avons :\n",
    "\n",
    "1. Chargé et préparé les données prétraitées par Part-1 bis\n",
    "2. Enrichi les données avec les codes postaux en utilisant les coordonnées géographiques\n",
    "3. Agrégé les données par mois, département et cluster\n",
    "4. Visualisé les tendances temporelles des prix et des transactions\n",
    "5. Analysé la saisonnalité du marché immobilier\n",
    "6. Décomposé les séries temporelles pour identifier les tendances et la saisonnalité\n",
    "7. Modélisé et prévu l'évolution future des prix immobiliers\n",
    "8. Exporté les données préparées pour une utilisation ultérieure\n",
    "\n",
    "Les résultats montrent une tendance générale à la hausse des prix immobiliers en France, avec des variations significatives entre les départements et les clusters. La saisonnalité joue également un rôle important dans le marché immobilier, avec des pics d'activité à certaines périodes de l'année.\n",
    "\n",
    "Les prévisions suggèrent que cette tendance à la hausse devrait se poursuivre dans les mois à venir, mais avec des variations selon les régions et les types de zones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
