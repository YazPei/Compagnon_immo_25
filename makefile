
# ========== Makefile MLOps ==========
# Pipelines R√©gression + S√©ries temporelles
# Outils : DVC, MLflow, Docker, bash scripts
IMAGE_PREFIX=compagnon_immo
PYTHON_BIN=.venv/bin/python
DVC_TOKEN ?= default_token_s√©curis√©_ou_vide
.PHONY: prepare-dirs install docker_build help fusion preprocessing clustering regression series \
	ml-pipeline api-dev streamlit api-test dev-env mlflow-ui mlflow-clean mlflow-status \
	docker-build docker-api-build docker-api-run docker-stack-up docker-stack-down docker-logs \
	setup_dags docker_auto build-all run-all-docker run_full run_dvc run_fusion run_preprocessing \
	run_clustering run_lgbm run_analyse run_splitst run_decompose run_SARIMAX run_evaluate \
	build-dvc-image run-dvc-repro dvc-push dvc-pull dvc-metrics dvc-plots dvc-save \
	clean_exports clean_dvc clean_all mlflow-run mlflow-log-status test-ml test-all \
	full-stack quick-start status ports-check
	
# ===============================
# Aide
# ===============================

help: ## Affiche l'aide
	@echo "========== Compagnon Immo - Commandes disponibles =========="
	@echo ""
	@grep -E '^[a-zA-Z_-]+:.*?##.*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-30s\033[0m %s\n", $$1, $$2}'
	@echo ""


# ===============================
# üì¶ ligne de commande - test
# ===============================

quick-start-pipeline: build-all run-all-docker

# ===============================
# üåê API et Interface Web
# ===============================

api-dev: check-env ## D√©marre l'API en mode d√©veloppement
	@echo "üöÄ D√©marrage de l'API..."
	@echo "üìç API : http://localhost:8000"
	@echo "üìö Docs : http://localhost:8000/docs"
	nohup PYTHONPATH=api_test uvicorn app.routes.main:app --reload --host 0.0.0.0 --port 8000 > uvicorn.log 2>&1 &


api-test: check-env ## Lance les tests de l'API
	@echo "üß™ Tests de l'API..."
	@cd api_test && ../.venv/bin/python -m pytest app/tests/ -v

dev-env: ## Environnement de d√©veloppement complet
	@echo "üõ†Ô∏è D√©marrage de l'environnement complet..."
	@echo "D√©marrage en parall√®le : MLflow + API + Streamlit"
	@make -j3 mlflow-ui api-dev streamlit


# ===============================
# üìà MLflow
# ===============================

mlflow-ui: check-env ## D√©marre l'interface MLflow
	@echo "üìà D√©marrage de l'interface MLflow"
	@echo "üìç MLflow UI disponible sur : http://localhost:5001"
	@../.venv/bin/mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0 --port 5001

mlflow-clean: ## Nettoie les runs MLflow
	@echo "üßπ Suppression du r√©pertoire mlruns/"
	@rm -rf mlruns/

mlflow-status: ## Affiche le statut des derniers runs
	@echo "üìú Derniers runs MLflow"
	@find mlruns/ -name "meta.yaml" 2>/dev/null | xargs grep -H "status" || echo "Aucun run trouv√©"


# ===============================
# üê≥ Docker - API
# ===============================
prepare-dirs: ## Cr√©e les dossiers n√©cessaires au projet
	@echo "üìÅ Pr√©paration des dossiers requis..."
	@mkdir -p data exports mlruns
	@touch data/.gitkeep

docker-build: prepare-dirs ## Construction des images Docker
	@echo "üîß Construction des images..."
	@docker-compose build

docker-api-build: ## Construction de l'image Docker API
	@echo "Construction de l'image Docker API"
	@cd api_test && docker build -t compagnon-immo-api .

docker-api-run: docker-api-build ## Lance l'API dans Docker
	@echo "Lancement de l'API dans Docker"
	@echo "API disponible sur : http://localhost:8000"
	@docker run -d -p 8000:8000 --name compagnon-api compagnon-immo-api

docker-api-stop: ## Stoppe et supprime le conteneur API s'il existe
	@docker rm -f compagnon-api 2>/dev/null || echo "Aucun conteneur compagnon-api √† supprimer"


docker-stack-up: ## D√©marre la stack Docker compl√®te
	@echo "üê≥ D√©marrage de la stack..."
	@docker-compose up -d
	@echo "‚úÖ Stack d√©marr√©e"

docker-stack-down: ## Arr√™te la stack Docker
	@echo "üõë Arr√™t de la stack..."
	@docker-compose down

docker-logs: ## Affiche les logs Docker
	@docker-compose logs -f

# ===============================
# ‚òÅÔ∏è Setup remote DagsHub
# ===============================

setup_dags:  ## Configure le remote DVC vers DagsHub (secure, local only)
	@echo "‚òÅÔ∏è Configuration du remote DVC (DagsHub s√©curis√©)"
	@chmod +x setup_remote.sh
	@./setup_remote.sh

# 
# ===============================
# üê≥ Ex√©cution dans Docker
# ===============================


docker_auto: build-all run-all-docker

## builds ##
build-all: chmod-dvc-sh docker_build build-base build-fusion build-preprocessing build-clustering build-encoding build-lgbm build-analyse build-splitST build-decompose build-SARIMAX build-evaluate
	@echo "üì¶ Toutes les images Docker ont √©t√© construites avec succ√®s !"

chmod-dvc-sh: ## Rend ex√©cutable run_dvc.sh sur l'h√¥te
	@chmod +x mlops/2_dvc/run_dvc.sh

docker_build:
	@echo "üîß Construction de l‚Äôimage Docker..."
	docker build -f mlops/1_import_donnees/Dockerfile.run -t $(IMAGE_PREFIX)-run .

build-base: ## Build de l'image Docker de base (requirements install√©s)
	docker build -f mlops/2.dvc/Dockerfile.dvc -t $(IMAGE_PREFIX)-dvc .

build-fusion: ## Build de l'image Docker d'enrichissement du dataset
	docker build -f mlops/3.fusion/Dockerfile.fusion -t $(IMAGE_PREFIX)-fus .

build-preprocessing: ## Build de l'image Docker de preprocessing
	docker build -f mlops/4.preprocessing/Dockerfile.preprocessing -t $(IMAGE_PREFIX)-preprocess .

build-clustering: ## Build de l'image Docker de segmentation geographique
	docker build -f mlops/5.clustering/Dockerfile.clustering -t $(IMAGE_PREFIX)-clust .

build-encoding: ## Build de l'image Docker d'encoding
	docker build -f mlops/6.Regression/1.Encoding/Dockerfile.encoding.REG -t $(IMAGE_PREFIX)-encod .

build-lgbm: ## Build de l'image Docker de la modelisation Regression
	docker build -f mlops/6.Regression/2.LGBM/Dockerfile.lgbm.REG -t $(IMAGE_PREFIX)-lgbm .

build-util: ## Build de l'image Docker d'interpretabilit√©
	docker build -f mlops/6.Regression/3.UTILS/Dockerfile.util.REG -t $(IMAGE_PREFIX)-util .
		
build-analyse: ## Build de l'image Docker d'interpretabilit√©
	docker build -f mlops/6.Regression/4.Analyse/Dockerfile.analyse.REG -t $(IMAGE_PREFIX)-split-st .
	
build-splitst: ## Build de l'image Docker du Split de la serie temporelle
	docker build -f mlops/7.Serie_temporelle/1.SPLIT/Dockerfile.split.ST -t $(IMAGE_PREFIX)-decomp .

build-decompose: ## Build de l'image Docker de la d√©composition des courbes
	docker build -f mlops/7.Serie_temporelle/2.Decompose/Dockerfile.decompose.ST -t $(IMAGE_PREFIX)-sarimax .		

build-SARIMAX: ## Build de l'image Docker de la modelisation SARIMAX 
	docker build -f mlops/7.Serie_temporelle/3.SARIMAX/Dockerfile.sarimax.ST -t $(IMAGE_PREFIX)-sarimax .		
	
build-evaluate: ## Build de l'image Docker de l'√©valuation du mod√®le SARIMAX
	docker build -f mlops/7.Serie_temporelle/4.EVALUATE/Dockerfile.evaluate.ST -t $(IMAGE_PREFIX)-evalu .		

run-all-docker: run_full run_dvc run_fusion run_preprocessing run_clustering run_lgbm run_util run_analyse run_splitst run_decompose run_SARIMAX run_evaluate ## lancement de tous les containers 
	@echo "üöÄ Pipeline complet ex√©cut√© dans Docker !"

run_full:
	@echo "üöÄ Ex√©cution pipeline lancement"
	docker run --rm $(IMAGE_PREFIX)-run


run_dvc: chmod-dvc-sh ## lancement du dvc
	@echo "üß† Lancement DVC avec script run_dvc.sh (Docker)"
	docker run --rm \
		-e DVC_TOKEN=$(DVC_TOKEN) \
		-v $(PWD):/app \
		-w /app \
		$(IMAGE_PREFIX)-dvc
													
run_fusion: ## Lancement de la fusion des donn√©es (Docker)
	@echo "üåê Fusion des donn√©es IPS et g√©ographiques (Docker)"
	docker run --rm $(IMAGE_PREFIX)-fus

run_preprocessing: ## Lancement du preprocessing (Docker)
	@echo "üßº Ex√©cution preprocessing (Docker)"
	docker run --rm $(IMAGE_PREFIX)-preprocess

run_clustering: ## Lancement du clustering (Docker)
	@echo "üìä Ex√©cution du clustering (Docker)"
	docker run --rm $(IMAGE_PREFIX)-clust

run_encoding:
	docker run --rm $(IMAGE_PREFIX)-encod

	
run_lgbm: ## Lancement de la r√©gression LGBM (Docker)
	@echo "üîÅ Ex√©cution pipeline R√©gression (Docker)"
	docker run --rm $(IMAGE_PREFIX)-lgbm
	
run-util: ## Build de l'image Docker d'interpretabilit√©
	docker run --rm $(IMAGE_PREFIX)-util
	
run_analyse: ## Build de l'image Docker d'interpretabilit√©
	docker run --rm $(IMAGE_PREFIX)-shap

run_splitst: ## Split s√©rie temporelle
	docker run --rm $(IMAGE_PREFIX)-split-st

				
run_decompose: ## Build de l'image Docker de la d√©composition des courbes
	docker run --rm $(IMAGE_PREFIX)-decomp
			
run_SARIMAX: ## Build de l'image Docker de la modelisation SARIMAX 
	docker run --rm $(IMAGE_PREFIX)-sarimax		

run_evaluate: ## Build de l'image Docker de l'√©valuation du mod√®le SARIMAX
	docker run --rm $(IMAGE_PREFIX)-evalu	

		
# ===============================
# üìÅ Commandes DVC (via Docker)
# ===============================
dvc-all: build-dvc-image run-dvc-repro dvc-metrics dvc-push dvc-save ## Reproduit, affiche les m√©triques et push
	@echo "‚úÖ Pipeline DVC complet ex√©cut√© et synchronis√©"

build-cache: .venv/.pip_installed ## Build d√©pendances si requirements.txt modifi√©
	@echo "‚úÖ Build cache termin√© (si besoin)"
		
build-dvc-image: ## Build de l'image Docker DVC + DagsHub
	docker build -f Dockerfile.dvc -t $(IMAGE_PREFIX)-dvc .
	
run_dvc: ## lancement du dvc
	@echo "üß† Lancement DVC avec script run_dvc.sh (Docker)"
	docker run --rm \
		-e DVC_TOKEN=$(DVC_TOKEN) \
		-v $(PWD):/app \
		-w /app \
		$(IMAGE_PREFIX)-dvc
		
run-dvc-repro: ## Ex√©cution du pipeline DVC (repro) dans un conteneur DVC
	docker run --rm \
		-v $(PWD):/app \
		-v ~/.dvc/config.local:/app/.dvc/config.local:ro \
		-w /app \
		$(IMAGE_PREFIX)-dvc \
		dvc repro

	####	
dvc-push: ## Push vers DagsHub en Docker
	docker run --rm \
		-v $(PWD):/app \
		-v ~/.dvc/config.local:/app/.dvc/config.local:ro \
		-w /app \
		$(IMAGE_PREFIX)-dvc \
		push


dvc-pull: ## Pull depuis DagsHub en Docker
	docker run --rm \
		-v $(PWD):/app \
		-v ~/.dvc/config.local:/app/.dvc/config.local:ro \
		-w /app \
		$(IMAGE_PREFIX)-dvc \
		pull

dvc-metrics: ## Affiche les m√©triques DVC via Docker
	docker run --rm \
		-v $(PWD):/app \
		-v ~/.dvc/config.local:/app/.dvc/config.local:ro \
		-w /app \
		$(IMAGE_PREFIX)-dvc \
		metrics show
		
dvc-plots: ## G√©n√®re les graphiques DVC (plots.html) via Docker
	docker run --rm \
		-v $(PWD):/app \
		-v ~/.dvc/config.local:/app/.dvc/config.local:ro \
		-w /app \
		$(IMAGE_PREFIX)-dvc \
		plots show --html > plots.html && echo "Fichier 'plots.html' g√©n√©r√©"
		
dvc-save: ## Ajoute, commit et tag un fichier .dvc modifi√©
	dvc add data/processed/train_clean.csv
	git add data/processed/train_clean.csv.dvc
	git commit -m "DVC update train_clean"
					
# ===============================
# üßπ Nettoyage
# ===============================

clean_exports:
	@echo "üßπ Suppression des fichiers exports/"
	rm -rf exports/reg/*.csv exports/reg/*.joblib
	rm -rf exports/st/*.csv exports/st/*.pkl exports/st/*.png exports/st/*.json

clean_dvc:
	@echo "üßπ Nettoyage DVC cache non utilis√© (local uniquement)"
	dvc gc -w --force

clean_all: clean_exports clean_dvc




# ===============================
# üìà Tracking MLflow
# ===============================

mlflow-run:
	@echo "üöÄ Lancement manuel d‚Äôun run MLflow (ex: clustering)"
	python -m src.clustering \
		--input-path data/processed/train_clean.csv \
		--output-path data/interim

mlflow-clean:
	@echo "üßπ Suppression du r√©pertoire mlruns/"
	rm -rf mlruns/

mlflow-log-status:
	@echo "üìú Derniers runs MLflow"
	@find mlruns/ -name "meta.yaml" | xargs grep -H "status"


# ===============================
# üß™ Tests complets
# ===============================

test-ml: check-env ## Tests des pipelines ML
	@echo "üß™ Tests ML..."
	@pytest mlops/tests/ -v || echo "Dossier mlops/tests/ non trouv√©"

test-all: test-ml api-test ## Tous les tests
	@echo "‚úÖ Tous les tests termin√©s"

# ===============================
# üöÄ Pipelines complets
# ===============================

full-stack: install ml-pipeline api-dev ## Pipeline ML + API
	@echo "üéâ Pipeline complet + API d√©marr√©s !"

quick-start: install full-stack streamlit ## Installation et d√©marrage rapide
	@echo "üöÄ Projet pr√™t √† utiliser !"

# ===============================
# üîç Utilitaires
# ===============================

status: ## Affiche le statut du projet
	@echo "========== Statut du projet =========="
	@echo "Dossier : $(PWD)"
	@echo "Python : $$(python3 --version 2>/dev/null || echo 'Non install√©')"
	@echo "Env virtuel : $$([ -f .venv/bin/activate ] && echo '‚úÖ Pr√©sent' || echo '‚ùå Absent')"
	@echo "Docker : $$(docker --version 2>/dev/null || echo 'Non install√©')"
	@echo "DVC : $$(dvc --version 2>/dev/null || echo 'Non install√©')"
	@echo "Donn√©es : $$([ -d data ] && echo '‚úÖ Pr√©sent' || echo '‚ùå Absent')"

ports-check: ## V√©rifie les ports utilis√©s
	@echo "V√©rification des ports..."
	@echo "Port 8000 (API) : $$(lsof -ti:8000 && echo 'Occup√©' || echo 'Libre')"
	@echo "Port 8501 (Streamlit) : $$(lsof -ti:8501 && echo 'Occup√©' || echo 'Libre')"
	@echo "Port 5001 (MLflow) : $$(lsof -ti:5001 && echo 'Occup√©' || echo 'Libre')"
